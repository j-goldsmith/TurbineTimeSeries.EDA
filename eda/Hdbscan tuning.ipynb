{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import itertools\n",
    "import time\n",
    "from collections import Counter\n",
    "import hdbscan\n",
    "## get that here: https://github.com/scikit-learn-contrib/hdbscan\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import datetime \n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "pd.options.display.max_columns=300\n",
    "pd.options.display.max_rows=100\n",
    "# from TurbineTimeSeries.storage import MachineDataStore\n",
    "plt.rcParams[\"figure.figsize\"] = (14,8)\n",
    "#from TurbineTimeSeries.transformations import PCA, StandardScaler, DropCols, DropSparseCols, LeftJoin\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import AffinityPropagation, MeanShift, SpectralClustering, AgglomerativeClustering, DBSCAN\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# ## for agglomerative clustering, give linkage : {“ward”, “complete”, “average”}\n",
    "\n",
    "# n_clusts = 3\n",
    "# kmeans = KMeans(init='k-means++', n_clusters=n_clusts, n_init=10)\n",
    "# AffinityProp = AffinityPropagation()\n",
    "# Meanshift = MeanShift(n_jobs=7)\n",
    "# Spectral = SpectralClustering(n_clusters=n_clusts, affinity='nearest_neighbors',n_jobs=7)\n",
    "# Agglom_ward = AgglomerativeClustering(n_clusters=n_clusts, linkage='ward')\n",
    "# Agglom_complete = AgglomerativeClustering(n_clusters=n_clusts, linkage='complete')\n",
    "# Agglom_avg = AgglomerativeClustering(n_clusters=n_clusts, linkage='average')\n",
    "# Dbscan = DBSCAN(eps=5, min_samples=n_clusts)\n",
    "# GMM_spherical = GaussianMixture(n_components=n_clusts, covariance_type='spherical' )\n",
    "# GMM_diag = GaussianMixture(n_components=n_clusts, covariance_type='diag' )\n",
    "# GMM_tied = GaussianMixture(n_components=n_clusts, covariance_type='tied' )\n",
    "# GMM_full = GaussianMixture(n_components=n_clusts, covariance_type='full' )\n",
    "\n",
    "\n",
    "\n",
    "# clustering_algo_dict = {\n",
    "#                         'kmeans':kmeans, \n",
    "# #                         'AffinityProp': AffinityProp, #mem errors out. affinity propogation calculates full distance matrix so it's quadratic memory required. 10k samples would use ~80gb ram.\n",
    "#                         'Meanshift':Meanshift,  #runs forever\n",
    "#                         'Spectral':Spectral, ## runs forever\n",
    "# #                         'Agglom_ward':Agglom_ward, ## uses too much ram\n",
    "# #                         'Agglom_complete':Agglom_complete,\n",
    "# #                         'Agglom_avg':Agglom_avg,\n",
    "#                        'Dbscan':Dbscan,\n",
    "#                         'GMM_spherical':GMM_spherical,\n",
    "#                         'GMM_diag':GMM_diag, \n",
    "#                         'GMM_tied':GMM_tied,\n",
    "#                         'GMM_full':GMM_full\n",
    "#                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of model2 10min data:  (1602326, 76)\n"
     ]
    }
   ],
   "source": [
    "# model_number = 2\n",
    "\n",
    "# store = MachineDataStore('.config')\n",
    "\n",
    "# # model_data_hr = (store.query(model_number,'1hr')\n",
    "# #                  .not_null(['timestamp','psn'])\n",
    "# # #                  .exclude_psn([44,52,54,70])\n",
    "# #                  .execute())\n",
    "\n",
    "# model_data_min = (store.query(model_number,'10min')\n",
    "#                   .not_null(['timestamp','psn'])\n",
    "#                   .exclude_psn([44,52,54,70])\n",
    "#                   .execute())\n",
    "\n",
    "# model_data_min.head()\n",
    "# model1_1hr = pd.read_csv('../../../data/raw_data_model1.csv',index_col=0)\n",
    "# model2_1hr = pd.read_csv('../../../data/raw_data_model2.csv',index_col=0)\n",
    "\n",
    "# model1_10min = pd.read_csv('../../../data/raw_data_model1_10min.csv',index_col=0)\n",
    "model2_10min = pd.read_csv('../../../data/raw_data_model2_10min.csv')#,index_col=0)\n",
    "\n",
    "## convert all to timestamps\n",
    "# model1_1hr['timestamp'] = model1_1hr['timestamp'].apply(lambda x: pd.Timestamp(x))\n",
    "# model2_1hr['timestamp'] = model2_1hr['timestamp'].apply(lambda x: pd.Timestamp(x))\n",
    "# model1_10min['timestamp'] = model1_10min['timestamp'].apply(lambda x: pd.Timestamp(x))\n",
    "model2_10min['timestamp'] = model2_10min['timestamp'].apply(lambda x: pd.Timestamp(x))\n",
    "\n",
    "\n",
    "# print('Shape of model1 1hr data: ', model1_1hr.shape)\n",
    "# print('Shape of model2 1hr data: ', model2_1hr.shape)\n",
    "# print('Shape of model1 10min data: ', model1_10min.shape)\n",
    "print('Shape of model2 10min data: ', model2_10min.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2_10min=model2_10min.sort_values(by=['psn','timestamp'],ascending=(True,True))\n",
    "model2_10min=model2_10min.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dictionary = pd.read_csv('data_dictionary_model2.csv')\n",
    "# data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lo_c_brg1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [type(model2_10min.head()['timestamp'][0]) ## should be timestamp]\n",
    "[i for i in data_dictionary['COLUMN_NAME'].str.lower().values if i not in model2_10min.columns.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsystem_dict = {str(i).lower(): list(data_dictionary[data_dictionary['SUBSYSTEM']==i]['COLUMN_NAME'].str.lower().values) for i in data_dictionary['SUBSYSTEM'].unique()}\n",
    "del subsystem_dict['summary'] ## this group pretty useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gas path', 'fuel', 'generator', 'vibration', 'lube oil system', 'enclosure', 'package equipment']\n"
     ]
    }
   ],
   "source": [
    "print(list(subsystem_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gas path 29\n",
      "fuel 12\n",
      "generator 12\n",
      "vibration 6\n",
      "lube oil system 8\n",
      "enclosure 2\n",
      "package equipment 1\n"
     ]
    }
   ],
   "source": [
    "for i in subsystem_dict.keys():\n",
    "    print(i,len(subsystem_dict[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model2_10min.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsystem_pca(df,subsystem_dict,subsystems = [], psns = 'all'):\n",
    "    \n",
    "    subset = []\n",
    "    if isinstance(subsystems,list)==True:\n",
    "        if len(subsystems) > 0:\n",
    "            for i in subsystems:\n",
    "                subset = subset + subsystem_dict[i] ## populate subset with list of columns\n",
    "        else:\n",
    "            print('Empty list of subsystems detected. Using all subsystems for PCA')\n",
    "            subset = [s for L in subsystem_dict.keys() for s in subsystem_dict[L]]\n",
    "    else: \n",
    "        raise Exception('Please ensure subsystems parameter is a list')\n",
    "        \n",
    "    if psns == 'all' or isinstance(psns, (list, int))==True:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('Please provide a list of psns, single psn, or \"all\"')\n",
    "    \n",
    "\n",
    "\n",
    "    available_subset = [i for i in subset if i in df.columns.values]\n",
    "    if len(available_subset)<len(subset):\n",
    "        print('excluding columns: ', list(set(subset)-set(available_subset)))\n",
    "    available_subset =  available_subset + ['id','timestamp','psn']\n",
    "    model_data = df[available_subset]\n",
    "    \n",
    "    \n",
    "    \n",
    "    skipped_cols = ['sum_esn','sum_eng_st', 'sum_eng_h']\n",
    "    index_cols = ['id','timestamp','psn']\n",
    "    data_cols = [c for c in model_data.columns if (c not in index_cols) and (c not in skipped_cols)]\n",
    "    \n",
    "    missing_values = model_data.isnull().sum().sort_values()\n",
    "    sparse_cols = [x for x in missing_values.index if missing_values[x] > 30000]\n",
    "    clean_data_cols = [x for x in data_cols if x not in sparse_cols]\n",
    "    data = model_data[index_cols + clean_data_cols].dropna()#.reset_index()\n",
    "    print(data.shape)\n",
    "    clean_data = StandardScaler().fit_transform(data[clean_data_cols])\n",
    "\n",
    "    pca =  PCA().fit(clean_data)\n",
    "    reduced = pca.transform(clean_data)\n",
    "    reduced_df = pd.DataFrame(reduced)\n",
    "    reduced_df['psn'] = data.psn.values\n",
    "    reduced_df['timestamp'] = data.timestamp.values\n",
    "    return(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_eigs_subplots(reduced_df, n_eigs_x, n_eigs_y, psns, savefig = False,path=None,figname = None):\n",
    "    if isinstance(n_eigs_x,int) == True:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('n_eigs_x must be an integer')\n",
    "        \n",
    "    if isinstance(n_eigs_y,int) == True:\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('n_eigs_y must be an integer')\n",
    "    \n",
    "\n",
    "    \n",
    "    if psns == 'all':\n",
    "#         fig_base_title = 'All psns'\n",
    "        pass\n",
    "    elif isinstance(psns, list)==True:\n",
    "        model2_10min[model2_10min['psn'].isin(psns)]\n",
    "#         fig_base_title = 'PSN ' + str(psns)\n",
    "        \n",
    "    elif isinstance(psns,int) == True:\n",
    "        reduced_df = reduced_df[reduced_df['psn']==psns]\n",
    "#         fig_base_title = 'PSN ' + str(psns)\n",
    "    else:\n",
    "        raise Exception('Please provide a list of psns, single psn, or \"all\"')\n",
    "        \n",
    "    if path == None:\n",
    "        path = ''\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "        \n",
    "    f, axarr = plt.subplots(n_eigs_x, n_eigs_y)\n",
    "    f.set_figheight(40)\n",
    "    f.set_figwidth(40)\n",
    "    f.suptitle(path + fname,fontsize=16)\n",
    "    for i in range(n_eigs_x):\n",
    "        for j in range(n_eigs_y):\n",
    "\n",
    "            if i==j:\n",
    "                continue\n",
    "            axarr[i, j].scatter(reduced_df[i].values,reduced_df[j].values,3,alpha=0.5)\n",
    "            axarr[i, j].set_title('Eig '+str(i) + ' vs Eig '+ str(j))\n",
    "    if savefig == False:\n",
    "        plt.show()\n",
    "    else:\n",
    "        \n",
    "        f.savefig(path+str('\\\\') + fname +'.png')      \n",
    "#         f.suptitle(path + fig_base_title + ' ' + str(n_eigs_x) + 'x' + str(n_eigs_y) + ' subplots',fontsize=16)\n",
    "#         f.savefig(path + fig_base_title + ' ' + str(n_eigs_x) + 'x' + str(n_eigs_y) + ' subplots.png')\n",
    "#         plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looping through potential subsystems/tags to look for clusters in eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_pal = ['#33a02c', '#1f78b4', '#ff7f00', '#a6cee3','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#cab2d6','#6a3d9a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1602281, 76)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_10min.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list of subsystems detected. Using all subsystems for PCA\n",
      "excluding columns:  ['lo_c_brg1']\n",
      "(1602281, 72)\n",
      "(1602281, 71)\n"
     ]
    }
   ],
   "source": [
    "rd_df = subsystem_pca(model2_10min,subsystem_dict, [], psns = 'all')\n",
    "print(rd_df.shape)\n",
    "rd_df['id'] = model2_10min['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 (103217, 72)\n",
      "35 (71208, 72)\n",
      "36 (70287, 72)\n",
      "37 (65650, 72)\n",
      "38 (30025, 72)\n",
      "39 (22333, 72)\n",
      "40 (14024, 72)\n",
      "41 (15484, 72)\n",
      "42 (95461, 72)\n",
      "45 (48741, 72)\n",
      "46 (7592, 72)\n",
      "47 (10941, 72)\n",
      "48 (92989, 72)\n",
      "49 (89536, 72)\n",
      "50 (2516, 72)\n",
      "51 (5462, 72)\n",
      "53 (36714, 72)\n",
      "55 (77340, 72)\n",
      "56 (80596, 72)\n",
      "57 (65672, 72)\n",
      "58 (58907, 72)\n",
      "59 (66452, 72)\n",
      "60 (27075, 72)\n",
      "61 (17242, 72)\n",
      "62 (27185, 72)\n",
      "63 (1331, 72)\n",
      "64 (56204, 72)\n",
      "65 (51089, 72)\n",
      "66 (59654, 72)\n",
      "67 (57318, 72)\n",
      "68 (82581, 72)\n",
      "69 (12866, 72)\n",
      "71 (22779, 72)\n",
      "72 (55810, 72)\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(rd_df['psn'].unique()):\n",
    "    print(i, rd_df[rd_df['psn']==i].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hdbscan_eig_clusterer(reduced_df, cols, cluster_algo, cluster_params, psn='all'):\n",
    "    \"\"\"\n",
    "    reduced_df: dataframe output from a PCA\n",
    "    doesn't matter what index comes in, that's what will go out anywaysaaaaaa\n",
    "    \n",
    "    \"\"\"\n",
    "    ## todo: index by \n",
    "    returndf = pd.DataFrame()\n",
    "    psns = []\n",
    "    if psn == 'all':\n",
    "        psns = sorted(reduced_df['psn'].unique())\n",
    "    else:\n",
    "        psns = psn\n",
    "    \n",
    "    for pkg in psns:\n",
    "        tempdf = reduced_df[reduced['psn']==pkg]\n",
    "        min_clust_size = int(len(newdf)/70.3)+1\n",
    "        clusterer = cluster_algo(min_cluster_size=min_clust_size)\n",
    "        clusterer = clusterer.fit(tempdf[cols])\n",
    "        results = clusterer.predict(tempdf[cols])\n",
    "        tempdf['cluster'] = results\n",
    "        returndf = returndf.append(tempdf)\n",
    "    return(reduced_df)\n",
    "\n",
    "def plot_clusters(cluster_df, x, y, colorpal, save_fig = False, directory=None, title=''):\n",
    "    plt.figure(figsize=(28,16))\n",
    "    for i in sorted(cluster_df['cluster'].unique()):\n",
    "        tempdf = cluster_df[cluster_df['cluster']==i]\n",
    "        plt.scatter(tempdf[x].values,tempdf[y].values,s=3,alpha=0.5,c=color_pal[i],label = 'cluster '+str(i))\n",
    "    plt.xlabel('Eigenvector '+str(x))\n",
    "    plt.ylabel('Eigenvector '+str(y))\n",
    "    fulltitle = 'Eig '+str(x) + ' vs Eig ' + str(y)+' '+ str(title)#' Clustering using HDBSCAN 20eigs')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    if save_fig == True:\n",
    "        if directory != None:\n",
    "            plt.savefig(directory + title + 'png')\n",
    "        else:\n",
    "            plt.savefig(title+'.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sure final code returns df with psn,timestamp index and cluster num col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# num_eigs_toclust = 20 ## 20 eigenvectors cover 90% variance\n",
    "\n",
    "# current_directory = os.getcwd()\n",
    "# final_directory = os.path.join(current_directory,r'Hdbscan Clustering mc lendiv70')\n",
    "# if not os.path.isdir(final_directory):\n",
    "#     os.mkdir(final_directory)\n",
    "\n",
    "# # for psn in sorted(rd_df['psn'].unique()):\n",
    "# # def clusterandplot(rd_df, psn, num_eigs_toclust):\n",
    "# # for psn in sorted(rd_df['psn'].unique()):\n",
    "# for psn in [35,37,40,45,46,47,49,55,57,58,62]:\n",
    "#     print('started: ',psn)\n",
    "#     nao = time.time()\n",
    "#     newdf = rd_df[rd_df['psn']==psn]\n",
    "#     min_clust_size = int(len(newdf)/70.3)+1\n",
    "# #     hdbscan = hdbscan.HDBSCAN(min_cluster_size=min_clust_size) ## 70.3 chosen arbitrarily\n",
    "#     print('    clustering with min_cluster_size={} min_samples={}.....'.format(min_clust_size,int(min_clust_size)),end=\"\",flush=True)\n",
    "# #     cluster_results = cluster_eigs(reduced_df=rd_df, psn=psn, cols=list(range(num_eigs_toclust)), cluster_algo=hdbscan)\n",
    "#     clusterer = hdbscan.HDBSCAN(min_cluster_size=min_clust_size, min_samples=int(min_clust_size))\n",
    "#     clusterer_results = clusterer.fit_predict(newdf[list(range(num_eigs_toclust))])\n",
    "#     print(newdf.shape, len(clusterer_results))\n",
    "#     print('finished in {} seconds'.format(time.time()-nao))\n",
    "#     newdf['cluster'] = clusterer_results\n",
    "#     figname = 'PSN '+str(psn)+'HDBSCAN Clustering 20eigs minsize='+str(min_clust_size)\n",
    "#     print('    saving figure.....',end=\"\",flush=True)\n",
    "#     plot_clusters(newdf, x=0, y=1, colorpal = color_pal, save_fig=True, directory=final_directory+'\\\\', title = figname)\n",
    "#     print('finished in total {} seconds'.format(time.time()-nao))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_power_step (df,powercol,jump = 0.2):\n",
    "    ## function will return another dataframe where the power columns is replace with 1s and 0s. 1 represents an outlier.\n",
    "    ## jumps is a percentage\n",
    "    ## assumes data coming in is sorted by psn by timestamp.\n",
    "\n",
    "    \n",
    "    df = df[[powercol,'timestamp','psn']]\n",
    "\n",
    "    df = df.where((pd.notnull(df)),np.nan) ## replaces nulls with nans for math stuffs.\n",
    "    df2 = pd.DataFrame(index = df.index.values[1:],columns = df.columns.values)\n",
    "    df2['timestamp'] = df['timestamp'].values[1:]\n",
    "    ## np.divide will divide the first parameter by the second parameter so the resulting series starts\n",
    "    ## from the original dataframe's 1st item, not the 0th item.\n",
    "#     shifted = pd.Series(np.subtract(df[powercol].values[1:],df[powercol].values[:-1]),index=df.index.values[:-1])\n",
    "\n",
    "    shifted = pd.Series(np.divide(df[powercol].values[:-1],df[powercol].values[1:]),index=df.index.values[1:])-1\n",
    "\n",
    "    ## take all values and subtract from previous values. if unchanging, then result will be 0\n",
    "    ## create numpy array of all False\n",
    "\n",
    "    tomap = np.zeros(len(df2),dtype=int)  \n",
    "    \n",
    "    \n",
    "    ## find where jumps in data are greater than given jump parameter, and set numpy array equal to True in those positions\n",
    "    for j in shifted[abs(shifted)>=jump].index.values:\n",
    "        ## for now just doing where power jumps.\n",
    "        ## does not catch all in betweens since transients are only 10-20 mins long.\n",
    "        if (df.loc[j]['timestamp'] - df.loc[j-1]['timestamp']) > pd.Timedelta('12 minutes'): ## if data is not continuous\n",
    "            continue\n",
    "                        \n",
    "        else:\n",
    "            tomap[j] = True\n",
    "\n",
    "\n",
    "    \n",
    "    ## map back numpy array to df2\n",
    "    df2[powercol] = pd.Series(tomap).loc[1:]\n",
    "\n",
    "    df2.loc[0] = [0,df.loc[0]['timestamp'],0] ## assume not outlier for row 0. this also 0-indexes the dataframe again\n",
    "#     df2 = df2.sort_index()\n",
    "    df2['psn'] = df['psn']\n",
    "    return(df2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate different cluster parameters using powerstep function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5376, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_10min_powerstep = find_power_step(model2_10min,'perf_pow',jump=0.3)\n",
    "model2_10min['powerjump'] = model2_10min_powerstep['perf_pow']\n",
    "model2_10min['powerjump'] = model2_10min['powerjump'].fillna(0).astype(int)\n",
    "model2_10min_powerstep[model2_10min_powerstep['perf_pow']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1602280"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model2_10min_powerstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1596905, 1: 5376})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(model2_10min['powerjump'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clust_sizer: 110, sample_sizer: 0.2, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  606\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  512\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  2\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  5\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  8\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  125\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  63\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  80\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  15\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  37\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  183\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  46\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  27\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  21\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  57\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  31\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 110, sample_sizer: 0.2, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  47\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  525\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  5\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  115\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  49\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  17\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  233\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  30\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  63\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  39\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  31\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  83\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  73\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 0.4, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  529\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  5\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  2\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of powerjumps:  178\n",
      "number of noise by cluster:  64\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  58\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  18\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  45\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  33\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  60\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  51\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  33\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  102\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  69\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  11\n",
      "clust_sizer: 110, sample_sizer: 0.6, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  538\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  11\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  31\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  19\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  52\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  61\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  65\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  56\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  34\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  112\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  77\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 0.8, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  525\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  18\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  33\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  87\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  19\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  98\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  36\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of powerjumps:  440\n",
      "number of noise by cluster:  64\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  60\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  38\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  119\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  79\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  13\n",
      "clust_sizer: 110, sample_sizer: 1, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  534\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  25\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  19\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  90\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  18\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  233\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  100\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  73\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  65\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  67\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  38\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  125\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  84\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  13\n",
      "clust_sizer: 110, sample_sizer: 1.2, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  11\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  540\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  724\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  11\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  72\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  90\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  19\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  233\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  102\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  72\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  67\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  70\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  40\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  122\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  109\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  15\n",
      "clust_sizer: 110, sample_sizer: 1.4, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  19\n",
      "saving files\n",
      "done\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  617\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of powerjumps:  546\n",
      "number of noise by cluster:  521\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  2\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  8\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  124\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  28\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  82\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  15\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  24\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  181\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  46\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  82\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  25\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  40\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  31\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 0.2, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  47\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  520\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  25\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  5\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  8\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  114\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  36\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  17\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  233\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  34\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  30\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  71\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  31\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  79\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  69\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 0.4, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  528\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  5\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  2\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  61\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  58\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  18\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  42\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  54\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  63\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  49\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  32\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  98\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  65\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 0.6, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  534\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  8\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  11\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  107\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  38\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  18\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  50\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  57\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  64\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  56\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  33\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  109\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  77\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 0.8, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  526\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  9\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  17\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  32\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  19\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  97\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  34\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  64\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of powerjumps:  200\n",
      "number of noise by cluster:  59\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  115\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  78\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 1, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  541\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  25\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  18\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  36\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  87\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  18\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  232\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  98\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  36\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  65\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  62\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  38\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  122\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  81\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  13\n",
      "clust_sizer: 120, sample_sizer: 1.2, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  11\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 34\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  43\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 35\n",
      "number of powerjumps:  635\n",
      "number of noise by cluster:  635\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 36\n",
      "number of powerjumps:  546\n",
      "number of noise by cluster:  534\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 37\n",
      "number of powerjumps:  94\n",
      "number of noise by cluster:  26\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 38\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 39\n",
      "number of powerjumps:  15\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 40\n",
      "number of powerjumps:  52\n",
      "number of noise by cluster:  6\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 41\n",
      "number of powerjumps:  34\n",
      "number of noise by cluster:  7\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 42\n",
      "number of powerjumps:  725\n",
      "number of noise by cluster:  724\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 45\n",
      "number of powerjumps:  36\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 46\n",
      "number of powerjumps:  14\n",
      "number of noise by cluster:  3\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 47\n",
      "number of powerjumps:  27\n",
      "number of noise by cluster:  12\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 48\n",
      "number of powerjumps:  178\n",
      "number of noise by cluster:  19\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 49\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  46\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 50\n",
      "number of powerjumps:  16\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 51\n",
      "number of powerjumps:  21\n",
      "number of noise by cluster:  1\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 53\n",
      "number of powerjumps:  47\n",
      "number of noise by cluster:  44\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 55\n",
      "number of powerjumps:  90\n",
      "number of noise by cluster:  90\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 56\n",
      "number of powerjumps:  100\n",
      "number of noise by cluster:  18\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 57\n",
      "number of powerjumps:  10\n",
      "number of noise by cluster:  10\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 58\n",
      "number of powerjumps:  5\n",
      "number of noise by cluster:  4\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 59\n",
      "number of powerjumps:  233\n",
      "number of noise by cluster:  233\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 60\n",
      "number of powerjumps:  447\n",
      "number of noise by cluster:  101\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 61\n",
      "number of powerjumps:  228\n",
      "number of noise by cluster:  72\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 62\n",
      "number of powerjumps:  440\n",
      "number of noise by cluster:  66\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 63\n",
      "number of powerjumps:  1\n",
      "number of noise by cluster:  0\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 64\n",
      "number of powerjumps:  200\n",
      "number of noise by cluster:  69\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 65\n",
      "number of powerjumps:  206\n",
      "number of noise by cluster:  40\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 66\n",
      "number of powerjumps:  272\n",
      "number of noise by cluster:  124\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 67\n",
      "number of powerjumps:  223\n",
      "number of noise by cluster:  84\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 68\n",
      "number of powerjumps:  48\n",
      "number of noise by cluster:  48\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 69\n",
      "number of powerjumps:  35\n",
      "number of noise by cluster:  35\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 71\n",
      "number of powerjumps:  62\n",
      "number of noise by cluster:  13\n",
      "clust_sizer: 120, sample_sizer: 1.4, psn: 72\n",
      "number of powerjumps:  68\n",
      "number of noise by cluster:  14\n",
      "saving files\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "cluster_sizes = [110,120]#[40,50,60,70,80,90,100,110,120]#[10,20,30,40,50,60,70,80,90,100,110]\n",
    "min_sample_sizes = [0.2,0.4,0.6,0.8,1,1.2,1.4]\n",
    "psns = sorted(list(set(rd_df['psn'].values)))#[35,37,40,45,46,47,49,55,57,58,62]\n",
    "\n",
    "mindex0 = list(sorted(itertools.chain(*[range(len(cluster_sizes))for i in min_sample_sizes])))\n",
    "mindex1 = list(itertools.chain(*[range(len(min_sample_sizes))for i in cluster_sizes]))\n",
    "\n",
    "my_index = pd.MultiIndex(levels=[cluster_sizes,min_sample_sizes],\n",
    "                             labels=[mindex0,mindex1],\n",
    "                             names=[u'min_cluster_size', u'min_samples'])\n",
    "\n",
    "\n",
    "# transients_scores_df = pd.DataFrame(index=my_index,columns=psns)\n",
    "# normals_scores_df = pd.DataFrame(index=my_index,columns=psns)\n",
    "## slice df like this:  testdf.loc[10].loc[0.1][35]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_eigs_toclust = 20\n",
    "\n",
    "for clust_sizer in cluster_sizes:\n",
    "    transients_scores_df = pd.DataFrame(index=my_index,columns=psns)\n",
    "    normals_scores_df = pd.DataFrame(index=my_index,columns=psns)\n",
    "    for sample_sizer in min_sample_sizes:\n",
    "        for psn in psns:\n",
    "            print('clust_sizer: {}, sample_sizer: {}, psn: {}'.format(clust_sizer,sample_sizer,psn))\n",
    "\n",
    "            powerjump_validation = model2_10min[model2_10min['psn']==psn]['powerjump'].values\n",
    "            newdf = rd_df[rd_df['psn']==psn]\n",
    "            min_clust_size = int(len(newdf)/clust_sizer)+1\n",
    "            clusterer = hdbscan.HDBSCAN(min_cluster_size=min_clust_size, min_samples=int(min_clust_size*sample_sizer),core_dist_n_jobs=-1)\n",
    "            clusterer_results = clusterer.fit_predict(newdf[list(range(num_eigs_toclust))])\n",
    "            preds = [1 if i==-1 else 0 for i in clusterer_results]\n",
    "            \n",
    "            idxs_of_ones = []\n",
    "            for i,j in enumerate(powerjump_validation):\n",
    "                if j == 1:\n",
    "                    idxs_of_ones.append(i)\n",
    "            transient_validation = [powerjump_validation[i] for i in idxs_of_ones]\n",
    "            transient_predictions = [preds[i] for i in idxs_of_ones]\n",
    "            print('number of powerjumps: ', len(transient_validation))\n",
    "            print('number of noise by cluster: ', Counter(transient_predictions)[1])\n",
    "            f1score = metrics.f1_score(transient_validation, transient_predictions,average='micro')\n",
    "            ## use micro to take into account false pos/neg\n",
    "            transients_scores_df.loc[clust_sizer].loc[sample_sizer][psn]= f1score\n",
    "            \n",
    "            idxs_of_zeroes = []\n",
    "            for i,j in enumerate(powerjump_validation):\n",
    "                if j == 0:\n",
    "                    idxs_of_zeroes.append(i)\n",
    "            normals_validation = [powerjump_validation[i] for i in idxs_of_zeroes]\n",
    "            normals_predictions = [preds[i] for i in idxs_of_zeroes]\n",
    "            f1score_norm = metrics.f1_score(normals_validation, normals_predictions,average='micro')\n",
    "            normals_scores_df.loc[clust_sizer].loc[sample_sizer][psn]= f1score_norm\n",
    "    print('saving files')\n",
    "    transients_scores_df.to_csv('transients_scores_clust_'+str(clust_sizer)+'.csv')\n",
    "    normals_scores_df.to_csv('normals_scores_clust_'+str(clust_sizer)+'.csv')        \n",
    "    print('done')        \n",
    "            \n",
    "            \n",
    "# newdf['cluster'] = clusterer_results\n",
    "## min_clust size/70 gives 256 \"noise\" datapoints\n",
    "## min clust size/40 gives  \"noise\" datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transients_scores_df.to_csv('transients_scores_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normals_scores_df.to_csv('normals_scores_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todo: join dfs together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tran_tojoin = glob.glob('transients_scores_clust*')\n",
    "transients_scores_df = pd.DataFrame()\n",
    "for i in tran_tojoin:\n",
    "    transients_scores_df = transients_scores_df.append(pd.read_csv(i))\n",
    "transients_scores_df = transients_scores_df.dropna().set_index(['min_cluster_size','min_samples']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>53</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>min_samples</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">40</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.819149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>0.233010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.093960</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.155340</td>\n",
       "      <td>0.360294</td>\n",
       "      <td>0.291480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.826923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.410112</td>\n",
       "      <td>0.174757</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.219239</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.184466</td>\n",
       "      <td>0.448529</td>\n",
       "      <td>0.363229</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.237864</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228188</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>0.433824</td>\n",
       "      <td>0.385650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286517</td>\n",
       "      <td>0.237864</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230425</td>\n",
       "      <td>0.179825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.247573</td>\n",
       "      <td>0.488971</td>\n",
       "      <td>0.434978</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.826923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.325843</td>\n",
       "      <td>0.257282</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237136</td>\n",
       "      <td>0.201754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.276699</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.417040</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.807692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.378641</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.957447</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241611</td>\n",
       "      <td>0.407895</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.421525</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.365169</td>\n",
       "      <td>0.388350</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.239374</td>\n",
       "      <td>0.214912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.286408</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.426009</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    34   35        36        37   38   39  \\\n",
       "min_cluster_size min_samples                                                \n",
       "40               0.2          0.923077  1.0  0.967033  0.819149  1.0  0.8   \n",
       "                 0.4          0.826923  1.0  1.000000  0.851064  1.0  0.8   \n",
       "                 0.6          0.846154  1.0  1.000000  0.882979  1.0  0.8   \n",
       "                 0.8          0.846154  1.0  1.000000  0.893617  1.0  0.8   \n",
       "                 1.0          0.826923  1.0  1.000000  0.851064  1.0  0.8   \n",
       "                 1.2          0.807692  1.0  1.000000  0.872340  1.0  0.8   \n",
       "                 1.4          0.769231  1.0  1.000000  0.925532  1.0  0.8   \n",
       "\n",
       "                                    40        41   42        45        46  \\\n",
       "min_cluster_size min_samples                                                \n",
       "40               0.2          0.096154  0.176471  1.0  0.972222  0.142857   \n",
       "                 0.4          0.115385  0.205882  1.0  0.972222  0.214286   \n",
       "                 0.6          0.134615  0.205882  1.0  0.972222  0.214286   \n",
       "                 0.8          0.153846  0.205882  1.0  0.972222  0.214286   \n",
       "                 1.0          0.173077  0.205882  1.0  0.972222  0.214286   \n",
       "                 1.2          0.173077  0.205882  1.0  0.972222  0.000000   \n",
       "                 1.4          0.173077  0.205882  1.0  0.972222  0.071429   \n",
       "\n",
       "                                    47        48        49      50        51  \\\n",
       "min_cluster_size min_samples                                                   \n",
       "40               0.2          0.111111  0.556180  0.233010  0.0000  0.047619   \n",
       "                 0.4          0.148148  0.410112  0.174757  0.0000  0.047619   \n",
       "                 0.6          0.000000  0.398876  0.237864  0.0000  0.095238   \n",
       "                 0.8          0.000000  0.286517  0.237864  0.0000  0.095238   \n",
       "                 1.0          0.185185  0.325843  0.257282  0.0625  0.095238   \n",
       "                 1.2          0.185185  0.359551  0.378641  0.0625  0.095238   \n",
       "                 1.4          0.222222  0.365169  0.388350  0.0625  0.095238   \n",
       "\n",
       "                                    53        55    56   57   58        59  \\\n",
       "min_cluster_size min_samples                                                 \n",
       "40               0.2          0.936170  0.966667  0.97  1.0  0.8  0.995708   \n",
       "                 0.4          0.936170  0.988889  0.96  1.0  0.8  0.995708   \n",
       "                 0.6          0.936170  0.977778  0.97  1.0  0.8  1.000000   \n",
       "                 0.8          0.957447  0.977778  0.98  1.0  0.8  1.000000   \n",
       "                 1.0          0.957447  0.977778  0.97  1.0  0.8  1.000000   \n",
       "                 1.2          0.957447  0.977778  0.98  1.0  0.8  1.000000   \n",
       "                 1.4          0.978723  0.977778  0.98  1.0  0.8  1.000000   \n",
       "\n",
       "                                    60        61   62   63     64        65  \\\n",
       "min_cluster_size min_samples                                                  \n",
       "40               0.2          0.093960  0.236842  1.0  1.0  0.245  0.155340   \n",
       "                 0.4          0.219239  0.157895  1.0  1.0  0.310  0.184466   \n",
       "                 0.6          0.228188  0.333333  1.0  1.0  0.365  0.194175   \n",
       "                 0.8          0.230425  0.179825  1.0  1.0  0.400  0.247573   \n",
       "                 1.0          0.237136  0.201754  1.0  1.0  0.430  0.276699   \n",
       "                 1.2          0.241611  0.407895  1.0  1.0  0.470  0.344660   \n",
       "                 1.4          0.239374  0.214912  1.0  1.0  0.490  0.286408   \n",
       "\n",
       "                                    66        67        68   69        71   72  \n",
       "min_cluster_size min_samples                                                    \n",
       "40               0.2          0.360294  0.291480  1.000000  1.0  0.161290  1.0  \n",
       "                 0.4          0.448529  0.363229  1.000000  1.0  0.209677  1.0  \n",
       "                 0.6          0.433824  0.385650  1.000000  1.0  0.274194  1.0  \n",
       "                 0.8          0.488971  0.434978  0.979167  1.0  0.290323  1.0  \n",
       "                 1.0          0.500000  0.417040  0.958333  1.0  0.322581  1.0  \n",
       "                 1.2          0.525735  0.421525  0.958333  1.0  0.322581  1.0  \n",
       "                 1.4          0.529412  0.426009  0.958333  1.0  0.370968  1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transients_scores_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 0.9230769230769232\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 0.9255319148936171\n",
      "38 1.0\n",
      "39 0.8000000000000002\n",
      "40 0.17307692307692307\n",
      "41 0.2058823529411765\n",
      "42 1.0\n",
      "45 0.9722222222222222\n",
      "46 0.5714285714285714\n",
      "47 0.4814814814814815\n",
      "48 0.702247191011236\n",
      "49 0.3883495145631068\n",
      "50 0.0625\n",
      "51 0.09523809523809523\n",
      "53 0.9787234042553192\n",
      "55 1.0\n",
      "56 0.98\n",
      "57 1.0\n",
      "58 0.8000000000000002\n",
      "59 1.0\n",
      "60 0.2460850111856823\n",
      "61 0.8026315789473685\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 0.49\n",
      "65 0.3446601941747573\n",
      "66 0.5294117647058824\n",
      "67 0.4887892376681615\n",
      "68 1.0\n",
      "69 1.0\n",
      "71 0.3709677419354839\n",
      "72 1.0\n",
      "Counter({1.4: 140, 1.2: 124, 1.0: 108, 0.8: 97, 0.4: 90, 0.6: 89, 0.2: 80})\n",
      "Counter({40: 119, 50: 109, 60: 93, 70: 82, 80: 76, 90: 70, 100: 66, 110: 60, 120: 53})\n"
     ]
    }
   ],
   "source": [
    "mylist = []\n",
    "for col in transients_scores_df.columns:\n",
    "    print(col,transients_scores_df[col].max())\n",
    "    ## grabs the rows where f1 score is max\n",
    "    mylist.append(transients_scores_df[transients_scores_df[col]==transients_scores_df[col].max()][col])\n",
    "print(Counter([x[1] for ii in mylist for x in ii.index.values ])) ## counts number of times that the min_samples multipler appears\n",
    "print(Counter([x[0] for ii in mylist for x in ii.index.values ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_tojoin = glob.glob('normals_scores_clust*')\n",
    "normals_scores_df = pd.DataFrame()\n",
    "for i in norm_tojoin:\n",
    "    normals_scores_df = normals_scores_df.append(pd.read_csv(i))\n",
    "normals_scores_df = normals_scores_df.dropna().set_index(['min_cluster_size','min_samples']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>53</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_cluster_size</th>\n",
       "      <th>min_samples</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">40</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.763331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287378</td>\n",
       "      <td>0.711087</td>\n",
       "      <td>0.900483</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.743189</td>\n",
       "      <td>0.992478</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.785726</td>\n",
       "      <td>0.880925</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>0.998713</td>\n",
       "      <td>0.713366</td>\n",
       "      <td>0.877282</td>\n",
       "      <td>0.824202</td>\n",
       "      <td>0.927386</td>\n",
       "      <td>0.985382</td>\n",
       "      <td>0.992887</td>\n",
       "      <td>0.993428</td>\n",
       "      <td>0.949630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341353</td>\n",
       "      <td>0.994643</td>\n",
       "      <td>0.994635</td>\n",
       "      <td>0.982352</td>\n",
       "      <td>0.991610</td>\n",
       "      <td>0.776938</td>\n",
       "      <td>0.782480</td>\n",
       "      <td>0.996963</td>\n",
       "      <td>0.359460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.825435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620081</td>\n",
       "      <td>0.850575</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996421</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613838</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.961151</td>\n",
       "      <td>0.846117</td>\n",
       "      <td>0.983667</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.997427</td>\n",
       "      <td>0.612104</td>\n",
       "      <td>0.753631</td>\n",
       "      <td>0.738024</td>\n",
       "      <td>0.871920</td>\n",
       "      <td>0.976605</td>\n",
       "      <td>0.991015</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>0.981956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991161</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.975312</td>\n",
       "      <td>0.981277</td>\n",
       "      <td>0.700702</td>\n",
       "      <td>0.494038</td>\n",
       "      <td>0.996302</td>\n",
       "      <td>0.336371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.770077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501388</td>\n",
       "      <td>0.792171</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656729</td>\n",
       "      <td>0.982449</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.822747</td>\n",
       "      <td>0.970010</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.986951</td>\n",
       "      <td>0.568849</td>\n",
       "      <td>0.714330</td>\n",
       "      <td>0.592166</td>\n",
       "      <td>0.833161</td>\n",
       "      <td>0.964025</td>\n",
       "      <td>0.972878</td>\n",
       "      <td>0.974238</td>\n",
       "      <td>0.879041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.984180</td>\n",
       "      <td>0.992846</td>\n",
       "      <td>0.974352</td>\n",
       "      <td>0.977021</td>\n",
       "      <td>0.655459</td>\n",
       "      <td>0.433170</td>\n",
       "      <td>0.995686</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.738157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460965</td>\n",
       "      <td>0.871531</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614927</td>\n",
       "      <td>0.975851</td>\n",
       "      <td>0.999725</td>\n",
       "      <td>0.953497</td>\n",
       "      <td>0.967547</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.986767</td>\n",
       "      <td>0.513923</td>\n",
       "      <td>0.673618</td>\n",
       "      <td>0.640218</td>\n",
       "      <td>0.790823</td>\n",
       "      <td>0.951071</td>\n",
       "      <td>0.965312</td>\n",
       "      <td>0.972998</td>\n",
       "      <td>0.965205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.991471</td>\n",
       "      <td>0.969014</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.622066</td>\n",
       "      <td>0.380563</td>\n",
       "      <td>0.994894</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.713992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.532934</td>\n",
       "      <td>0.620490</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.993988</td>\n",
       "      <td>0.998252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549779</td>\n",
       "      <td>0.965690</td>\n",
       "      <td>0.994686</td>\n",
       "      <td>0.946687</td>\n",
       "      <td>0.964614</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>0.986400</td>\n",
       "      <td>0.518477</td>\n",
       "      <td>0.638084</td>\n",
       "      <td>0.669387</td>\n",
       "      <td>0.749977</td>\n",
       "      <td>0.933619</td>\n",
       "      <td>0.951343</td>\n",
       "      <td>0.970219</td>\n",
       "      <td>0.960562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979037</td>\n",
       "      <td>0.989407</td>\n",
       "      <td>0.967111</td>\n",
       "      <td>0.972082</td>\n",
       "      <td>0.695819</td>\n",
       "      <td>0.354064</td>\n",
       "      <td>0.994013</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.732458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474632</td>\n",
       "      <td>0.549792</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.993630</td>\n",
       "      <td>0.998252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537275</td>\n",
       "      <td>0.997493</td>\n",
       "      <td>0.994502</td>\n",
       "      <td>0.918684</td>\n",
       "      <td>0.934087</td>\n",
       "      <td>0.9624</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.471678</td>\n",
       "      <td>0.592647</td>\n",
       "      <td>0.613037</td>\n",
       "      <td>0.710822</td>\n",
       "      <td>0.926607</td>\n",
       "      <td>0.939881</td>\n",
       "      <td>0.969205</td>\n",
       "      <td>0.827495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976252</td>\n",
       "      <td>0.982273</td>\n",
       "      <td>0.962817</td>\n",
       "      <td>0.971784</td>\n",
       "      <td>0.693589</td>\n",
       "      <td>0.347596</td>\n",
       "      <td>0.993001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.747356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376289</td>\n",
       "      <td>0.753956</td>\n",
       "      <td>0.997939</td>\n",
       "      <td>0.992843</td>\n",
       "      <td>0.998188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535510</td>\n",
       "      <td>0.997361</td>\n",
       "      <td>0.994319</td>\n",
       "      <td>0.913006</td>\n",
       "      <td>0.928445</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.986032</td>\n",
       "      <td>0.384815</td>\n",
       "      <td>0.567392</td>\n",
       "      <td>0.567320</td>\n",
       "      <td>0.665332</td>\n",
       "      <td>0.921531</td>\n",
       "      <td>0.925248</td>\n",
       "      <td>0.967853</td>\n",
       "      <td>0.956154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972752</td>\n",
       "      <td>0.984474</td>\n",
       "      <td>0.961015</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.685096</td>\n",
       "      <td>0.338010</td>\n",
       "      <td>0.988467</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">50</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.074079</td>\n",
       "      <td>0.329964</td>\n",
       "      <td>0.993380</td>\n",
       "      <td>0.936732</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998068</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.161797</td>\n",
       "      <td>0.767375</td>\n",
       "      <td>0.966614</td>\n",
       "      <td>0.985065</td>\n",
       "      <td>0.818513</td>\n",
       "      <td>0.910724</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.998713</td>\n",
       "      <td>0.729130</td>\n",
       "      <td>0.881864</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.945037</td>\n",
       "      <td>0.986724</td>\n",
       "      <td>0.987134</td>\n",
       "      <td>0.994742</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.741559</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>0.995304</td>\n",
       "      <td>0.994831</td>\n",
       "      <td>0.984625</td>\n",
       "      <td>0.957054</td>\n",
       "      <td>0.742236</td>\n",
       "      <td>0.809134</td>\n",
       "      <td>0.997315</td>\n",
       "      <td>0.506422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.839984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152235</td>\n",
       "      <td>0.641147</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997495</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673750</td>\n",
       "      <td>0.988783</td>\n",
       "      <td>0.984332</td>\n",
       "      <td>0.775393</td>\n",
       "      <td>0.986388</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.997427</td>\n",
       "      <td>0.654430</td>\n",
       "      <td>0.823832</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.898617</td>\n",
       "      <td>0.980238</td>\n",
       "      <td>0.991558</td>\n",
       "      <td>0.978369</td>\n",
       "      <td>0.985130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0.994026</td>\n",
       "      <td>0.977653</td>\n",
       "      <td>0.982345</td>\n",
       "      <td>0.716332</td>\n",
       "      <td>0.480867</td>\n",
       "      <td>0.996522</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.810158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220631</td>\n",
       "      <td>0.600494</td>\n",
       "      <td>0.836415</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671225</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>0.976636</td>\n",
       "      <td>0.834287</td>\n",
       "      <td>0.971353</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.997243</td>\n",
       "      <td>0.626258</td>\n",
       "      <td>0.749670</td>\n",
       "      <td>0.999019</td>\n",
       "      <td>0.856553</td>\n",
       "      <td>0.973023</td>\n",
       "      <td>0.976517</td>\n",
       "      <td>0.975777</td>\n",
       "      <td>0.887504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987697</td>\n",
       "      <td>0.993554</td>\n",
       "      <td>0.974454</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.685144</td>\n",
       "      <td>0.429974</td>\n",
       "      <td>0.996038</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.764523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501922</td>\n",
       "      <td>0.781742</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995419</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635582</td>\n",
       "      <td>0.981394</td>\n",
       "      <td>0.967565</td>\n",
       "      <td>0.819407</td>\n",
       "      <td>0.969518</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986951</td>\n",
       "      <td>0.557231</td>\n",
       "      <td>0.696880</td>\n",
       "      <td>0.649361</td>\n",
       "      <td>0.824998</td>\n",
       "      <td>0.961394</td>\n",
       "      <td>0.971232</td>\n",
       "      <td>0.973900</td>\n",
       "      <td>0.875044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983394</td>\n",
       "      <td>0.992610</td>\n",
       "      <td>0.973292</td>\n",
       "      <td>0.975935</td>\n",
       "      <td>0.667612</td>\n",
       "      <td>0.430130</td>\n",
       "      <td>0.995466</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.737993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460949</td>\n",
       "      <td>0.871198</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614927</td>\n",
       "      <td>0.975851</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.806607</td>\n",
       "      <td>0.967547</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986583</td>\n",
       "      <td>0.513732</td>\n",
       "      <td>0.673618</td>\n",
       "      <td>0.624130</td>\n",
       "      <td>0.790655</td>\n",
       "      <td>0.951003</td>\n",
       "      <td>0.965297</td>\n",
       "      <td>0.972961</td>\n",
       "      <td>0.965205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.991471</td>\n",
       "      <td>0.968997</td>\n",
       "      <td>0.971714</td>\n",
       "      <td>0.622066</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.994894</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.726070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499008</td>\n",
       "      <td>0.638681</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.993988</td>\n",
       "      <td>0.998252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563802</td>\n",
       "      <td>0.969121</td>\n",
       "      <td>0.994961</td>\n",
       "      <td>0.947991</td>\n",
       "      <td>0.965443</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>0.986400</td>\n",
       "      <td>0.468323</td>\n",
       "      <td>0.645929</td>\n",
       "      <td>0.627013</td>\n",
       "      <td>0.758886</td>\n",
       "      <td>0.937286</td>\n",
       "      <td>0.954968</td>\n",
       "      <td>0.970520</td>\n",
       "      <td>0.961444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979519</td>\n",
       "      <td>0.989938</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.972064</td>\n",
       "      <td>0.586044</td>\n",
       "      <td>0.363806</td>\n",
       "      <td>0.994189</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.733223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487659</td>\n",
       "      <td>0.567583</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.993773</td>\n",
       "      <td>0.998252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.531116</td>\n",
       "      <td>0.965294</td>\n",
       "      <td>0.994502</td>\n",
       "      <td>0.929082</td>\n",
       "      <td>0.936326</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>0.490114</td>\n",
       "      <td>0.613411</td>\n",
       "      <td>0.630975</td>\n",
       "      <td>0.721117</td>\n",
       "      <td>0.922057</td>\n",
       "      <td>0.943536</td>\n",
       "      <td>0.968905</td>\n",
       "      <td>0.958799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977269</td>\n",
       "      <td>0.986243</td>\n",
       "      <td>0.964484</td>\n",
       "      <td>0.971679</td>\n",
       "      <td>0.695637</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.993529</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">60</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.808559</td>\n",
       "      <td>0.085571</td>\n",
       "      <td>0.393771</td>\n",
       "      <td>0.993563</td>\n",
       "      <td>0.940830</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998425</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.178813</td>\n",
       "      <td>0.829401</td>\n",
       "      <td>0.973212</td>\n",
       "      <td>0.981583</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.924684</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.998713</td>\n",
       "      <td>0.737148</td>\n",
       "      <td>0.892466</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.814748</td>\n",
       "      <td>0.987674</td>\n",
       "      <td>0.988251</td>\n",
       "      <td>0.995606</td>\n",
       "      <td>0.989656</td>\n",
       "      <td>0.986053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.995244</td>\n",
       "      <td>0.986511</td>\n",
       "      <td>0.964813</td>\n",
       "      <td>0.772406</td>\n",
       "      <td>0.785442</td>\n",
       "      <td>0.997711</td>\n",
       "      <td>0.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.852295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237622</td>\n",
       "      <td>0.993212</td>\n",
       "      <td>0.881759</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997638</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.261136</td>\n",
       "      <td>0.699415</td>\n",
       "      <td>0.990367</td>\n",
       "      <td>0.984607</td>\n",
       "      <td>0.737607</td>\n",
       "      <td>0.987630</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.998713</td>\n",
       "      <td>0.689230</td>\n",
       "      <td>0.845592</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.912308</td>\n",
       "      <td>0.982768</td>\n",
       "      <td>0.991830</td>\n",
       "      <td>0.991963</td>\n",
       "      <td>0.931174</td>\n",
       "      <td>0.987773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993411</td>\n",
       "      <td>0.994261</td>\n",
       "      <td>0.979573</td>\n",
       "      <td>0.986409</td>\n",
       "      <td>0.676033</td>\n",
       "      <td>0.751929</td>\n",
       "      <td>0.996699</td>\n",
       "      <td>0.418195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.823477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129465</td>\n",
       "      <td>0.992876</td>\n",
       "      <td>0.846777</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996421</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613838</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.973520</td>\n",
       "      <td>0.846117</td>\n",
       "      <td>0.983667</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.997427</td>\n",
       "      <td>0.636785</td>\n",
       "      <td>0.778977</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.871828</td>\n",
       "      <td>0.976605</td>\n",
       "      <td>0.991015</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>0.981956</td>\n",
       "      <td>0.986689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991161</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.975296</td>\n",
       "      <td>0.981277</td>\n",
       "      <td>0.700702</td>\n",
       "      <td>0.492947</td>\n",
       "      <td>0.996302</td>\n",
       "      <td>0.336371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.786720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121378</td>\n",
       "      <td>0.991763</td>\n",
       "      <td>0.816492</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995706</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673894</td>\n",
       "      <td>0.984297</td>\n",
       "      <td>0.968756</td>\n",
       "      <td>0.826648</td>\n",
       "      <td>0.970693</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.610958</td>\n",
       "      <td>0.730356</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.970697</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.975064</td>\n",
       "      <td>0.885976</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985876</td>\n",
       "      <td>0.993239</td>\n",
       "      <td>0.974437</td>\n",
       "      <td>0.978404</td>\n",
       "      <td>0.676941</td>\n",
       "      <td>0.438080</td>\n",
       "      <td>0.995950</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.761751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490100</td>\n",
       "      <td>0.770381</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995276</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625069</td>\n",
       "      <td>0.980206</td>\n",
       "      <td>0.958219</td>\n",
       "      <td>0.817748</td>\n",
       "      <td>0.969204</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986767</td>\n",
       "      <td>0.550004</td>\n",
       "      <td>0.710667</td>\n",
       "      <td>0.996745</td>\n",
       "      <td>0.819332</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.970462</td>\n",
       "      <td>0.973787</td>\n",
       "      <td>0.873457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983073</td>\n",
       "      <td>0.992394</td>\n",
       "      <td>0.972534</td>\n",
       "      <td>0.975199</td>\n",
       "      <td>0.665019</td>\n",
       "      <td>0.427792</td>\n",
       "      <td>0.995422</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.737993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460949</td>\n",
       "      <td>0.871198</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614927</td>\n",
       "      <td>0.975851</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.806607</td>\n",
       "      <td>0.967547</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986583</td>\n",
       "      <td>0.513923</td>\n",
       "      <td>0.673515</td>\n",
       "      <td>0.624130</td>\n",
       "      <td>0.790655</td>\n",
       "      <td>0.951071</td>\n",
       "      <td>0.965312</td>\n",
       "      <td>0.972961</td>\n",
       "      <td>0.965205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.991471</td>\n",
       "      <td>0.968997</td>\n",
       "      <td>0.971714</td>\n",
       "      <td>0.622066</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.994894</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.726807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456373</td>\n",
       "      <td>0.651308</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.998252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574171</td>\n",
       "      <td>0.970177</td>\n",
       "      <td>0.995327</td>\n",
       "      <td>0.979755</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.986583</td>\n",
       "      <td>0.476559</td>\n",
       "      <td>0.650783</td>\n",
       "      <td>0.632727</td>\n",
       "      <td>0.764765</td>\n",
       "      <td>0.939679</td>\n",
       "      <td>0.957097</td>\n",
       "      <td>0.970933</td>\n",
       "      <td>0.961855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979734</td>\n",
       "      <td>0.989977</td>\n",
       "      <td>0.967515</td>\n",
       "      <td>0.971679</td>\n",
       "      <td>0.591788</td>\n",
       "      <td>0.367469</td>\n",
       "      <td>0.994453</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">70</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.831464</td>\n",
       "      <td>0.078968</td>\n",
       "      <td>0.439842</td>\n",
       "      <td>0.994524</td>\n",
       "      <td>0.874863</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998712</td>\n",
       "      <td>0.998835</td>\n",
       "      <td>0.202626</td>\n",
       "      <td>0.836013</td>\n",
       "      <td>0.975059</td>\n",
       "      <td>0.982225</td>\n",
       "      <td>0.826734</td>\n",
       "      <td>0.934714</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.998713</td>\n",
       "      <td>0.741457</td>\n",
       "      <td>0.872828</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.856645</td>\n",
       "      <td>0.988201</td>\n",
       "      <td>0.989021</td>\n",
       "      <td>0.996019</td>\n",
       "      <td>0.990008</td>\n",
       "      <td>0.986577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.995460</td>\n",
       "      <td>0.987959</td>\n",
       "      <td>0.995043</td>\n",
       "      <td>0.783141</td>\n",
       "      <td>0.805471</td>\n",
       "      <td>0.998767</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.864014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261525</td>\n",
       "      <td>0.993303</td>\n",
       "      <td>0.897818</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.717873</td>\n",
       "      <td>0.991423</td>\n",
       "      <td>0.973704</td>\n",
       "      <td>0.763853</td>\n",
       "      <td>0.989343</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.998713</td>\n",
       "      <td>0.715439</td>\n",
       "      <td>0.863508</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0.920807</td>\n",
       "      <td>0.984126</td>\n",
       "      <td>0.992691</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>0.932644</td>\n",
       "      <td>0.988895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994036</td>\n",
       "      <td>0.994379</td>\n",
       "      <td>0.981021</td>\n",
       "      <td>0.990612</td>\n",
       "      <td>0.695419</td>\n",
       "      <td>0.536435</td>\n",
       "      <td>0.996919</td>\n",
       "      <td>0.999139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.833946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270415</td>\n",
       "      <td>0.993090</td>\n",
       "      <td>0.848209</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997495</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656750</td>\n",
       "      <td>0.987860</td>\n",
       "      <td>0.976910</td>\n",
       "      <td>0.983170</td>\n",
       "      <td>0.987529</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.997427</td>\n",
       "      <td>0.646740</td>\n",
       "      <td>0.808828</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.979050</td>\n",
       "      <td>0.991498</td>\n",
       "      <td>0.977880</td>\n",
       "      <td>0.984307</td>\n",
       "      <td>0.987362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992161</td>\n",
       "      <td>0.993986</td>\n",
       "      <td>0.976996</td>\n",
       "      <td>0.982012</td>\n",
       "      <td>0.712127</td>\n",
       "      <td>0.487257</td>\n",
       "      <td>0.996434</td>\n",
       "      <td>0.998672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.815616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222538</td>\n",
       "      <td>0.992434</td>\n",
       "      <td>0.838781</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612011</td>\n",
       "      <td>0.985616</td>\n",
       "      <td>0.971138</td>\n",
       "      <td>0.838133</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.997427</td>\n",
       "      <td>0.632612</td>\n",
       "      <td>0.757087</td>\n",
       "      <td>0.999304</td>\n",
       "      <td>0.860939</td>\n",
       "      <td>0.974110</td>\n",
       "      <td>0.977469</td>\n",
       "      <td>0.976040</td>\n",
       "      <td>0.886740</td>\n",
       "      <td>0.985792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988715</td>\n",
       "      <td>0.993554</td>\n",
       "      <td>0.974571</td>\n",
       "      <td>0.980261</td>\n",
       "      <td>0.690294</td>\n",
       "      <td>0.453511</td>\n",
       "      <td>0.996082</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.771279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127185</td>\n",
       "      <td>0.991320</td>\n",
       "      <td>0.802299</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671266</td>\n",
       "      <td>0.983109</td>\n",
       "      <td>0.964266</td>\n",
       "      <td>0.824396</td>\n",
       "      <td>0.970223</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.987135</td>\n",
       "      <td>0.596176</td>\n",
       "      <td>0.733786</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>0.838689</td>\n",
       "      <td>0.965808</td>\n",
       "      <td>0.973603</td>\n",
       "      <td>0.974613</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.984633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984930</td>\n",
       "      <td>0.993043</td>\n",
       "      <td>0.974470</td>\n",
       "      <td>0.977651</td>\n",
       "      <td>0.679861</td>\n",
       "      <td>0.441275</td>\n",
       "      <td>0.995774</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.760423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118696</td>\n",
       "      <td>0.989703</td>\n",
       "      <td>0.764118</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995133</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616795</td>\n",
       "      <td>0.979810</td>\n",
       "      <td>0.956753</td>\n",
       "      <td>0.815981</td>\n",
       "      <td>0.969070</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986767</td>\n",
       "      <td>0.544577</td>\n",
       "      <td>0.705916</td>\n",
       "      <td>0.996410</td>\n",
       "      <td>0.815860</td>\n",
       "      <td>0.958643</td>\n",
       "      <td>0.969737</td>\n",
       "      <td>0.973562</td>\n",
       "      <td>0.872223</td>\n",
       "      <td>0.981791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982823</td>\n",
       "      <td>0.992335</td>\n",
       "      <td>0.972029</td>\n",
       "      <td>0.974709</td>\n",
       "      <td>0.661372</td>\n",
       "      <td>0.413530</td>\n",
       "      <td>0.995290</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.737993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460965</td>\n",
       "      <td>0.871531</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.994561</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614927</td>\n",
       "      <td>0.975851</td>\n",
       "      <td>0.953271</td>\n",
       "      <td>0.806607</td>\n",
       "      <td>0.967547</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986583</td>\n",
       "      <td>0.513732</td>\n",
       "      <td>0.673618</td>\n",
       "      <td>0.624130</td>\n",
       "      <td>0.790655</td>\n",
       "      <td>0.951071</td>\n",
       "      <td>0.965297</td>\n",
       "      <td>0.972998</td>\n",
       "      <td>0.965205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.991471</td>\n",
       "      <td>0.968997</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.622066</td>\n",
       "      <td>0.380563</td>\n",
       "      <td>0.994894</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">80</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.847836</td>\n",
       "      <td>0.084026</td>\n",
       "      <td>0.458009</td>\n",
       "      <td>0.996964</td>\n",
       "      <td>0.888056</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.998835</td>\n",
       "      <td>0.226651</td>\n",
       "      <td>0.856894</td>\n",
       "      <td>0.975851</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.810626</td>\n",
       "      <td>0.895959</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.741457</td>\n",
       "      <td>0.885838</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.880981</td>\n",
       "      <td>0.989202</td>\n",
       "      <td>0.969133</td>\n",
       "      <td>0.996507</td>\n",
       "      <td>0.988245</td>\n",
       "      <td>0.986315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996197</td>\n",
       "      <td>0.995598</td>\n",
       "      <td>0.988498</td>\n",
       "      <td>0.957702</td>\n",
       "      <td>0.774345</td>\n",
       "      <td>0.853480</td>\n",
       "      <td>0.998503</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.762701</td>\n",
       "      <td>0.061270</td>\n",
       "      <td>0.287378</td>\n",
       "      <td>0.993364</td>\n",
       "      <td>0.924338</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.182898</td>\n",
       "      <td>0.743065</td>\n",
       "      <td>0.992478</td>\n",
       "      <td>0.976544</td>\n",
       "      <td>0.785726</td>\n",
       "      <td>0.880678</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>0.877282</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0.927386</td>\n",
       "      <td>0.985382</td>\n",
       "      <td>0.992887</td>\n",
       "      <td>0.993428</td>\n",
       "      <td>0.949630</td>\n",
       "      <td>0.987886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994643</td>\n",
       "      <td>0.994635</td>\n",
       "      <td>0.982352</td>\n",
       "      <td>0.991610</td>\n",
       "      <td>0.711618</td>\n",
       "      <td>0.565350</td>\n",
       "      <td>0.996963</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.843862</td>\n",
       "      <td>0.055021</td>\n",
       "      <td>0.200298</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>0.866800</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.171730</td>\n",
       "      <td>0.688307</td>\n",
       "      <td>0.989179</td>\n",
       "      <td>0.979384</td>\n",
       "      <td>0.984334</td>\n",
       "      <td>0.988526</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.691112</td>\n",
       "      <td>0.831974</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.904389</td>\n",
       "      <td>0.981189</td>\n",
       "      <td>0.991468</td>\n",
       "      <td>0.991625</td>\n",
       "      <td>0.924004</td>\n",
       "      <td>0.987474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992965</td>\n",
       "      <td>0.994104</td>\n",
       "      <td>0.978394</td>\n",
       "      <td>0.983256</td>\n",
       "      <td>0.658028</td>\n",
       "      <td>0.489673</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.999013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.823477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129465</td>\n",
       "      <td>0.992892</td>\n",
       "      <td>0.846777</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996421</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.613120</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.973520</td>\n",
       "      <td>0.982847</td>\n",
       "      <td>0.983589</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.636785</td>\n",
       "      <td>0.769605</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.871920</td>\n",
       "      <td>0.976605</td>\n",
       "      <td>0.991015</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>0.981956</td>\n",
       "      <td>0.986689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991161</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.975312</td>\n",
       "      <td>0.981277</td>\n",
       "      <td>0.700702</td>\n",
       "      <td>0.494038</td>\n",
       "      <td>0.996302</td>\n",
       "      <td>0.998116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.799438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117191</td>\n",
       "      <td>0.992159</td>\n",
       "      <td>0.825054</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675044</td>\n",
       "      <td>0.985088</td>\n",
       "      <td>0.968298</td>\n",
       "      <td>0.826842</td>\n",
       "      <td>0.971107</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.620476</td>\n",
       "      <td>0.740751</td>\n",
       "      <td>0.997515</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>0.972004</td>\n",
       "      <td>0.975808</td>\n",
       "      <td>0.975439</td>\n",
       "      <td>0.888621</td>\n",
       "      <td>0.985380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986858</td>\n",
       "      <td>0.993416</td>\n",
       "      <td>0.974352</td>\n",
       "      <td>0.903056</td>\n",
       "      <td>0.681703</td>\n",
       "      <td>0.426077</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.997488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.765851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.791271</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656319</td>\n",
       "      <td>0.982449</td>\n",
       "      <td>0.962892</td>\n",
       "      <td>0.822747</td>\n",
       "      <td>0.969999</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986951</td>\n",
       "      <td>0.586195</td>\n",
       "      <td>0.733566</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>0.833161</td>\n",
       "      <td>0.963991</td>\n",
       "      <td>0.972878</td>\n",
       "      <td>0.974238</td>\n",
       "      <td>0.879041</td>\n",
       "      <td>0.984147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984180</td>\n",
       "      <td>0.992846</td>\n",
       "      <td>0.974352</td>\n",
       "      <td>0.976986</td>\n",
       "      <td>0.655459</td>\n",
       "      <td>0.433170</td>\n",
       "      <td>0.995686</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.758329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118424</td>\n",
       "      <td>0.989292</td>\n",
       "      <td>0.757754</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995133</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616508</td>\n",
       "      <td>0.979282</td>\n",
       "      <td>0.956020</td>\n",
       "      <td>0.815054</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986767</td>\n",
       "      <td>0.540622</td>\n",
       "      <td>0.700738</td>\n",
       "      <td>0.996049</td>\n",
       "      <td>0.812662</td>\n",
       "      <td>0.957896</td>\n",
       "      <td>0.966943</td>\n",
       "      <td>0.973524</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.980632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982662</td>\n",
       "      <td>0.992237</td>\n",
       "      <td>0.971675</td>\n",
       "      <td>0.974446</td>\n",
       "      <td>0.662862</td>\n",
       "      <td>0.422960</td>\n",
       "      <td>0.995246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">90</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.856967</td>\n",
       "      <td>0.473524</td>\n",
       "      <td>0.478886</td>\n",
       "      <td>0.997132</td>\n",
       "      <td>0.900716</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998855</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.999631</td>\n",
       "      <td>0.867858</td>\n",
       "      <td>0.976907</td>\n",
       "      <td>0.983324</td>\n",
       "      <td>0.823965</td>\n",
       "      <td>0.994380</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.744375</td>\n",
       "      <td>0.892531</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.890941</td>\n",
       "      <td>0.988489</td>\n",
       "      <td>0.971171</td>\n",
       "      <td>0.997784</td>\n",
       "      <td>0.991654</td>\n",
       "      <td>0.992148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996357</td>\n",
       "      <td>0.995834</td>\n",
       "      <td>0.989357</td>\n",
       "      <td>0.996865</td>\n",
       "      <td>0.802794</td>\n",
       "      <td>0.837113</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.787001</td>\n",
       "      <td>0.069120</td>\n",
       "      <td>0.299953</td>\n",
       "      <td>0.993303</td>\n",
       "      <td>0.920307</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998211</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.760497</td>\n",
       "      <td>0.944840</td>\n",
       "      <td>0.978651</td>\n",
       "      <td>0.805842</td>\n",
       "      <td>0.893317</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.727275</td>\n",
       "      <td>0.872259</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0.939752</td>\n",
       "      <td>0.986062</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>0.994029</td>\n",
       "      <td>0.930293</td>\n",
       "      <td>0.986839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994875</td>\n",
       "      <td>0.994772</td>\n",
       "      <td>0.983598</td>\n",
       "      <td>0.952255</td>\n",
       "      <td>0.729866</td>\n",
       "      <td>0.796275</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.852295</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.237622</td>\n",
       "      <td>0.993212</td>\n",
       "      <td>0.881759</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997638</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.699415</td>\n",
       "      <td>0.990367</td>\n",
       "      <td>0.970405</td>\n",
       "      <td>0.737607</td>\n",
       "      <td>0.987630</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.704148</td>\n",
       "      <td>0.841010</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.912308</td>\n",
       "      <td>0.982734</td>\n",
       "      <td>0.991830</td>\n",
       "      <td>0.991963</td>\n",
       "      <td>0.931174</td>\n",
       "      <td>0.987773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993411</td>\n",
       "      <td>0.994261</td>\n",
       "      <td>0.979590</td>\n",
       "      <td>0.986409</td>\n",
       "      <td>0.676033</td>\n",
       "      <td>0.753644</td>\n",
       "      <td>0.996699</td>\n",
       "      <td>0.999103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.831745</td>\n",
       "      <td>0.058478</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.993029</td>\n",
       "      <td>0.851508</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997495</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.647531</td>\n",
       "      <td>0.987596</td>\n",
       "      <td>0.975536</td>\n",
       "      <td>0.982944</td>\n",
       "      <td>0.985940</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.657567</td>\n",
       "      <td>0.795780</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.881134</td>\n",
       "      <td>0.978676</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.977655</td>\n",
       "      <td>0.983837</td>\n",
       "      <td>0.987175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992018</td>\n",
       "      <td>0.993967</td>\n",
       "      <td>0.976559</td>\n",
       "      <td>0.981907</td>\n",
       "      <td>0.707184</td>\n",
       "      <td>0.483361</td>\n",
       "      <td>0.996346</td>\n",
       "      <td>0.998547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.816856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225205</td>\n",
       "      <td>0.992571</td>\n",
       "      <td>0.841846</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996064</td>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>0.619793</td>\n",
       "      <td>0.985616</td>\n",
       "      <td>0.968114</td>\n",
       "      <td>0.965780</td>\n",
       "      <td>0.976313</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.996324</td>\n",
       "      <td>0.636512</td>\n",
       "      <td>0.756686</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.863605</td>\n",
       "      <td>0.974840</td>\n",
       "      <td>0.977786</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.886388</td>\n",
       "      <td>0.986016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989429</td>\n",
       "      <td>0.993613</td>\n",
       "      <td>0.974319</td>\n",
       "      <td>0.980489</td>\n",
       "      <td>0.691929</td>\n",
       "      <td>0.441821</td>\n",
       "      <td>0.996126</td>\n",
       "      <td>0.997829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.786720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121378</td>\n",
       "      <td>0.991763</td>\n",
       "      <td>0.813427</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995706</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520316</td>\n",
       "      <td>0.984297</td>\n",
       "      <td>0.961884</td>\n",
       "      <td>0.826648</td>\n",
       "      <td>0.970693</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.610958</td>\n",
       "      <td>0.730356</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.846563</td>\n",
       "      <td>0.970680</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.975064</td>\n",
       "      <td>0.885976</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.993239</td>\n",
       "      <td>0.974420</td>\n",
       "      <td>0.978404</td>\n",
       "      <td>0.676941</td>\n",
       "      <td>0.438080</td>\n",
       "      <td>0.995950</td>\n",
       "      <td>0.995946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.761799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131429</td>\n",
       "      <td>0.990573</td>\n",
       "      <td>0.785141</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995419</td>\n",
       "      <td>0.998382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644985</td>\n",
       "      <td>0.981789</td>\n",
       "      <td>0.955562</td>\n",
       "      <td>0.820668</td>\n",
       "      <td>0.969865</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.986951</td>\n",
       "      <td>0.578531</td>\n",
       "      <td>0.720427</td>\n",
       "      <td>0.997056</td>\n",
       "      <td>0.828272</td>\n",
       "      <td>0.962361</td>\n",
       "      <td>0.972032</td>\n",
       "      <td>0.973975</td>\n",
       "      <td>0.876984</td>\n",
       "      <td>0.983287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983858</td>\n",
       "      <td>0.992768</td>\n",
       "      <td>0.973847</td>\n",
       "      <td>0.976390</td>\n",
       "      <td>0.670447</td>\n",
       "      <td>0.430442</td>\n",
       "      <td>0.995598</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">100</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.870169</td>\n",
       "      <td>0.500829</td>\n",
       "      <td>0.531839</td>\n",
       "      <td>0.997270</td>\n",
       "      <td>0.907846</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>0.978094</td>\n",
       "      <td>0.983049</td>\n",
       "      <td>0.835117</td>\n",
       "      <td>0.994582</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>0.767802</td>\n",
       "      <td>0.894162</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.908379</td>\n",
       "      <td>0.988693</td>\n",
       "      <td>0.968982</td>\n",
       "      <td>0.996808</td>\n",
       "      <td>0.702363</td>\n",
       "      <td>0.991812</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996572</td>\n",
       "      <td>0.996404</td>\n",
       "      <td>0.991950</td>\n",
       "      <td>0.996970</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.845219</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.774100</td>\n",
       "      <td>0.074079</td>\n",
       "      <td>0.329964</td>\n",
       "      <td>0.993380</td>\n",
       "      <td>0.936732</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998068</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.767375</td>\n",
       "      <td>0.946688</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.818513</td>\n",
       "      <td>0.992298</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.735593</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.802321</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>0.987134</td>\n",
       "      <td>0.994742</td>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.987586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995304</td>\n",
       "      <td>0.994831</td>\n",
       "      <td>0.984625</td>\n",
       "      <td>0.957054</td>\n",
       "      <td>0.742115</td>\n",
       "      <td>0.809134</td>\n",
       "      <td>0.997315</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.859730</td>\n",
       "      <td>0.045839</td>\n",
       "      <td>0.246326</td>\n",
       "      <td>0.993303</td>\n",
       "      <td>0.904548</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999546</td>\n",
       "      <td>0.708100</td>\n",
       "      <td>0.991291</td>\n",
       "      <td>0.972787</td>\n",
       "      <td>0.989301</td>\n",
       "      <td>0.988783</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0.918141</td>\n",
       "      <td>0.983702</td>\n",
       "      <td>0.992479</td>\n",
       "      <td>0.992414</td>\n",
       "      <td>0.919008</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993840</td>\n",
       "      <td>0.994320</td>\n",
       "      <td>0.980567</td>\n",
       "      <td>0.990069</td>\n",
       "      <td>0.689179</td>\n",
       "      <td>0.528486</td>\n",
       "      <td>0.996787</td>\n",
       "      <td>0.999121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.838666</td>\n",
       "      <td>0.052428</td>\n",
       "      <td>0.152235</td>\n",
       "      <td>0.993136</td>\n",
       "      <td>0.857904</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997495</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.673750</td>\n",
       "      <td>0.988783</td>\n",
       "      <td>0.978285</td>\n",
       "      <td>0.775393</td>\n",
       "      <td>0.986388</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.668803</td>\n",
       "      <td>0.817890</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.898617</td>\n",
       "      <td>0.980204</td>\n",
       "      <td>0.991558</td>\n",
       "      <td>0.978369</td>\n",
       "      <td>0.891207</td>\n",
       "      <td>0.987400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0.994026</td>\n",
       "      <td>0.977653</td>\n",
       "      <td>0.982380</td>\n",
       "      <td>0.646348</td>\n",
       "      <td>0.480867</td>\n",
       "      <td>0.996522</td>\n",
       "      <td>0.998942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.823399</td>\n",
       "      <td>0.061355</td>\n",
       "      <td>0.129465</td>\n",
       "      <td>0.992876</td>\n",
       "      <td>0.846477</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996350</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.613120</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.973245</td>\n",
       "      <td>0.982847</td>\n",
       "      <td>0.983589</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.649085</td>\n",
       "      <td>0.771547</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.871828</td>\n",
       "      <td>0.976605</td>\n",
       "      <td>0.991015</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>0.883684</td>\n",
       "      <td>0.986689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991126</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.975296</td>\n",
       "      <td>0.981259</td>\n",
       "      <td>0.700702</td>\n",
       "      <td>0.492947</td>\n",
       "      <td>0.996302</td>\n",
       "      <td>0.998116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.807183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220631</td>\n",
       "      <td>0.992297</td>\n",
       "      <td>0.832417</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.238790</td>\n",
       "      <td>0.535612</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>0.969855</td>\n",
       "      <td>0.965133</td>\n",
       "      <td>0.971331</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.995773</td>\n",
       "      <td>0.626258</td>\n",
       "      <td>0.742951</td>\n",
       "      <td>0.999019</td>\n",
       "      <td>0.856553</td>\n",
       "      <td>0.972989</td>\n",
       "      <td>0.976517</td>\n",
       "      <td>0.975777</td>\n",
       "      <td>0.887504</td>\n",
       "      <td>0.985642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987697</td>\n",
       "      <td>0.993554</td>\n",
       "      <td>0.974454</td>\n",
       "      <td>0.979700</td>\n",
       "      <td>0.685144</td>\n",
       "      <td>0.429974</td>\n",
       "      <td>0.996038</td>\n",
       "      <td>0.997722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.776184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127558</td>\n",
       "      <td>0.991564</td>\n",
       "      <td>0.803098</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516641</td>\n",
       "      <td>0.983901</td>\n",
       "      <td>0.964724</td>\n",
       "      <td>0.825495</td>\n",
       "      <td>0.970290</td>\n",
       "      <td>0.9824</td>\n",
       "      <td>0.987135</td>\n",
       "      <td>0.600322</td>\n",
       "      <td>0.736557</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.841567</td>\n",
       "      <td>0.966538</td>\n",
       "      <td>0.974071</td>\n",
       "      <td>0.974801</td>\n",
       "      <td>0.883214</td>\n",
       "      <td>0.984782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985162</td>\n",
       "      <td>0.993063</td>\n",
       "      <td>0.974386</td>\n",
       "      <td>0.977896</td>\n",
       "      <td>0.682212</td>\n",
       "      <td>0.445328</td>\n",
       "      <td>0.995862</td>\n",
       "      <td>0.417836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">110</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.881278</td>\n",
       "      <td>0.483159</td>\n",
       "      <td>0.514016</td>\n",
       "      <td>0.997331</td>\n",
       "      <td>0.979810</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998926</td>\n",
       "      <td>0.998900</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.998481</td>\n",
       "      <td>0.960940</td>\n",
       "      <td>0.976086</td>\n",
       "      <td>0.826562</td>\n",
       "      <td>0.810176</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.997243</td>\n",
       "      <td>0.773311</td>\n",
       "      <td>0.899689</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.989118</td>\n",
       "      <td>0.970326</td>\n",
       "      <td>0.996019</td>\n",
       "      <td>0.702892</td>\n",
       "      <td>0.992858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996554</td>\n",
       "      <td>0.996443</td>\n",
       "      <td>0.990452</td>\n",
       "      <td>0.997110</td>\n",
       "      <td>0.815383</td>\n",
       "      <td>0.863923</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.793670</td>\n",
       "      <td>0.082369</td>\n",
       "      <td>0.354526</td>\n",
       "      <td>0.993441</td>\n",
       "      <td>0.935199</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998211</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>0.997659</td>\n",
       "      <td>0.971364</td>\n",
       "      <td>0.980117</td>\n",
       "      <td>0.780155</td>\n",
       "      <td>0.856801</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.748275</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.999516</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.986673</td>\n",
       "      <td>0.987632</td>\n",
       "      <td>0.995306</td>\n",
       "      <td>0.989420</td>\n",
       "      <td>0.987250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995572</td>\n",
       "      <td>0.995028</td>\n",
       "      <td>0.985450</td>\n",
       "      <td>0.961363</td>\n",
       "      <td>0.759963</td>\n",
       "      <td>0.818175</td>\n",
       "      <td>0.997579</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.867659</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.277082</td>\n",
       "      <td>0.993303</td>\n",
       "      <td>0.902549</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.999536</td>\n",
       "      <td>0.728118</td>\n",
       "      <td>0.991686</td>\n",
       "      <td>0.974620</td>\n",
       "      <td>0.823275</td>\n",
       "      <td>0.868577</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.711130</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.984669</td>\n",
       "      <td>0.992676</td>\n",
       "      <td>0.993090</td>\n",
       "      <td>0.987011</td>\n",
       "      <td>0.989007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.994438</td>\n",
       "      <td>0.981526</td>\n",
       "      <td>0.991015</td>\n",
       "      <td>0.701283</td>\n",
       "      <td>0.549840</td>\n",
       "      <td>0.996919</td>\n",
       "      <td>0.999139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.845946</td>\n",
       "      <td>0.060590</td>\n",
       "      <td>0.209819</td>\n",
       "      <td>0.993181</td>\n",
       "      <td>0.871064</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997567</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.693399</td>\n",
       "      <td>0.989311</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>0.984840</td>\n",
       "      <td>0.987126</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.996876</td>\n",
       "      <td>0.692721</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>0.999330</td>\n",
       "      <td>0.981512</td>\n",
       "      <td>0.991558</td>\n",
       "      <td>0.991625</td>\n",
       "      <td>0.920889</td>\n",
       "      <td>0.987586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993072</td>\n",
       "      <td>0.994202</td>\n",
       "      <td>0.978680</td>\n",
       "      <td>0.984062</td>\n",
       "      <td>0.665043</td>\n",
       "      <td>0.499026</td>\n",
       "      <td>0.996654</td>\n",
       "      <td>0.999013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.830253</td>\n",
       "      <td>0.061624</td>\n",
       "      <td>0.281785</td>\n",
       "      <td>0.993029</td>\n",
       "      <td>0.848476</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997423</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999641</td>\n",
       "      <td>0.640756</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.982922</td>\n",
       "      <td>0.985582</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.654321</td>\n",
       "      <td>0.786693</td>\n",
       "      <td>0.999441</td>\n",
       "      <td>0.879413</td>\n",
       "      <td>0.978354</td>\n",
       "      <td>0.991513</td>\n",
       "      <td>0.977430</td>\n",
       "      <td>0.983308</td>\n",
       "      <td>0.987063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991876</td>\n",
       "      <td>0.993888</td>\n",
       "      <td>0.976306</td>\n",
       "      <td>0.981715</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.493648</td>\n",
       "      <td>0.996346</td>\n",
       "      <td>0.998457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.818310</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>0.222136</td>\n",
       "      <td>0.992663</td>\n",
       "      <td>0.843711</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996135</td>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.999599</td>\n",
       "      <td>0.625542</td>\n",
       "      <td>0.985616</td>\n",
       "      <td>0.968389</td>\n",
       "      <td>0.982825</td>\n",
       "      <td>0.977723</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>0.996324</td>\n",
       "      <td>0.646494</td>\n",
       "      <td>0.759508</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.865371</td>\n",
       "      <td>0.975213</td>\n",
       "      <td>0.977831</td>\n",
       "      <td>0.976416</td>\n",
       "      <td>0.885800</td>\n",
       "      <td>0.986128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989786</td>\n",
       "      <td>0.993632</td>\n",
       "      <td>0.974369</td>\n",
       "      <td>0.980664</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>0.446341</td>\n",
       "      <td>0.996214</td>\n",
       "      <td>0.997865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.796065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118854</td>\n",
       "      <td>0.992037</td>\n",
       "      <td>0.822289</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.239898</td>\n",
       "      <td>0.523560</td>\n",
       "      <td>0.984429</td>\n",
       "      <td>0.967473</td>\n",
       "      <td>0.828048</td>\n",
       "      <td>0.970950</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.993935</td>\n",
       "      <td>0.617694</td>\n",
       "      <td>0.729748</td>\n",
       "      <td>0.997118</td>\n",
       "      <td>0.851071</td>\n",
       "      <td>0.971699</td>\n",
       "      <td>0.975581</td>\n",
       "      <td>0.975327</td>\n",
       "      <td>0.888210</td>\n",
       "      <td>0.985343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986608</td>\n",
       "      <td>0.993397</td>\n",
       "      <td>0.974538</td>\n",
       "      <td>0.901305</td>\n",
       "      <td>0.681170</td>\n",
       "      <td>0.443068</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.997291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">120</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.882567</td>\n",
       "      <td>0.434982</td>\n",
       "      <td>0.449836</td>\n",
       "      <td>0.997346</td>\n",
       "      <td>0.980010</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998998</td>\n",
       "      <td>0.998835</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.998481</td>\n",
       "      <td>0.963051</td>\n",
       "      <td>0.976544</td>\n",
       "      <td>0.767355</td>\n",
       "      <td>0.991515</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.997243</td>\n",
       "      <td>0.774048</td>\n",
       "      <td>0.893463</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.998625</td>\n",
       "      <td>0.971368</td>\n",
       "      <td>0.997071</td>\n",
       "      <td>0.705595</td>\n",
       "      <td>0.993382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985590</td>\n",
       "      <td>0.996404</td>\n",
       "      <td>0.992691</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.825246</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.998547</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.808559</td>\n",
       "      <td>0.085571</td>\n",
       "      <td>0.393771</td>\n",
       "      <td>0.993563</td>\n",
       "      <td>0.940830</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.998425</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999557</td>\n",
       "      <td>0.997762</td>\n",
       "      <td>0.954605</td>\n",
       "      <td>0.981583</td>\n",
       "      <td>0.778938</td>\n",
       "      <td>0.988973</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.737148</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>0.996486</td>\n",
       "      <td>0.988251</td>\n",
       "      <td>0.995606</td>\n",
       "      <td>0.989656</td>\n",
       "      <td>0.986053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>0.995244</td>\n",
       "      <td>0.986511</td>\n",
       "      <td>0.964813</td>\n",
       "      <td>0.770310</td>\n",
       "      <td>0.785442</td>\n",
       "      <td>0.997711</td>\n",
       "      <td>0.999193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.762701</td>\n",
       "      <td>0.061270</td>\n",
       "      <td>0.287378</td>\n",
       "      <td>0.993364</td>\n",
       "      <td>0.924338</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.999536</td>\n",
       "      <td>0.996263</td>\n",
       "      <td>0.992478</td>\n",
       "      <td>0.975994</td>\n",
       "      <td>0.835666</td>\n",
       "      <td>0.877454</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.718112</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.999478</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>0.994194</td>\n",
       "      <td>0.992887</td>\n",
       "      <td>0.993428</td>\n",
       "      <td>0.949630</td>\n",
       "      <td>0.987886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994643</td>\n",
       "      <td>0.994635</td>\n",
       "      <td>0.982352</td>\n",
       "      <td>0.991610</td>\n",
       "      <td>0.711618</td>\n",
       "      <td>0.782480</td>\n",
       "      <td>0.996963</td>\n",
       "      <td>0.999175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.852295</td>\n",
       "      <td>0.054511</td>\n",
       "      <td>0.237622</td>\n",
       "      <td>0.993212</td>\n",
       "      <td>0.881759</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997638</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.699415</td>\n",
       "      <td>0.990367</td>\n",
       "      <td>0.970405</td>\n",
       "      <td>0.737607</td>\n",
       "      <td>0.984630</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.704094</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.999376</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.991830</td>\n",
       "      <td>0.991963</td>\n",
       "      <td>0.931174</td>\n",
       "      <td>0.987773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993411</td>\n",
       "      <td>0.994261</td>\n",
       "      <td>0.979573</td>\n",
       "      <td>0.986409</td>\n",
       "      <td>0.675851</td>\n",
       "      <td>0.751929</td>\n",
       "      <td>0.996699</td>\n",
       "      <td>0.999103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.835584</td>\n",
       "      <td>0.052740</td>\n",
       "      <td>0.270601</td>\n",
       "      <td>0.993105</td>\n",
       "      <td>0.851374</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.997495</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>0.663546</td>\n",
       "      <td>0.988124</td>\n",
       "      <td>0.977277</td>\n",
       "      <td>0.983396</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.676657</td>\n",
       "      <td>0.999055</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.991498</td>\n",
       "      <td>0.978031</td>\n",
       "      <td>0.984836</td>\n",
       "      <td>0.987362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992322</td>\n",
       "      <td>0.993986</td>\n",
       "      <td>0.977249</td>\n",
       "      <td>0.982082</td>\n",
       "      <td>0.641489</td>\n",
       "      <td>0.485699</td>\n",
       "      <td>0.996478</td>\n",
       "      <td>0.998798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.823399</td>\n",
       "      <td>0.061582</td>\n",
       "      <td>0.129465</td>\n",
       "      <td>0.992876</td>\n",
       "      <td>0.846477</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.996421</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.613120</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.973245</td>\n",
       "      <td>0.982847</td>\n",
       "      <td>0.983589</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.996508</td>\n",
       "      <td>0.649276</td>\n",
       "      <td>0.767288</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.871828</td>\n",
       "      <td>0.976605</td>\n",
       "      <td>0.991015</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>0.981956</td>\n",
       "      <td>0.986689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991161</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.975296</td>\n",
       "      <td>0.981277</td>\n",
       "      <td>0.700702</td>\n",
       "      <td>0.492947</td>\n",
       "      <td>0.996302</td>\n",
       "      <td>0.998116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.812369</td>\n",
       "      <td>0.053037</td>\n",
       "      <td>0.223656</td>\n",
       "      <td>0.992358</td>\n",
       "      <td>0.835682</td>\n",
       "      <td>0.998253</td>\n",
       "      <td>0.995920</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.235972</td>\n",
       "      <td>0.543989</td>\n",
       "      <td>0.985616</td>\n",
       "      <td>0.966465</td>\n",
       "      <td>0.982804</td>\n",
       "      <td>0.972372</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.995957</td>\n",
       "      <td>0.640276</td>\n",
       "      <td>0.748298</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>0.858944</td>\n",
       "      <td>0.973804</td>\n",
       "      <td>0.976955</td>\n",
       "      <td>0.975928</td>\n",
       "      <td>0.887446</td>\n",
       "      <td>0.985717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988394</td>\n",
       "      <td>0.993534</td>\n",
       "      <td>0.974437</td>\n",
       "      <td>0.979998</td>\n",
       "      <td>0.687567</td>\n",
       "      <td>0.432234</td>\n",
       "      <td>0.996038</td>\n",
       "      <td>0.997775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    34        35        36        37  \\\n",
       "min_cluster_size min_samples                                           \n",
       "40               0.2          0.763331  0.000000  0.287378  0.711087   \n",
       "                 0.4          0.825435  0.000000  0.000000  0.620081   \n",
       "                 0.6          0.770077  0.000000  0.000000  0.501388   \n",
       "                 0.8          0.738157  0.000000  0.000000  0.460965   \n",
       "                 1.0          0.713992  0.000000  0.000000  0.532934   \n",
       "                 1.2          0.732458  0.000000  0.000000  0.474632   \n",
       "                 1.4          0.747356  0.000000  0.000000  0.376289   \n",
       "50               0.2          0.774100  0.074079  0.329964  0.993380   \n",
       "                 0.4          0.839984  0.000000  0.152235  0.641147   \n",
       "                 0.6          0.810158  0.000000  0.220631  0.600494   \n",
       "                 0.8          0.764523  0.000000  0.000000  0.501922   \n",
       "                 1.0          0.737993  0.000000  0.000000  0.460949   \n",
       "                 1.2          0.726070  0.000000  0.000000  0.499008   \n",
       "                 1.4          0.733223  0.000000  0.000000  0.487659   \n",
       "60               0.2          0.808559  0.085571  0.393771  0.993563   \n",
       "                 0.4          0.852295  0.000000  0.237622  0.993212   \n",
       "                 0.6          0.823477  0.000000  0.129465  0.992876   \n",
       "                 0.8          0.786720  0.000000  0.121378  0.991763   \n",
       "                 1.0          0.761751  0.000000  0.000000  0.490100   \n",
       "                 1.2          0.737993  0.000000  0.000000  0.460949   \n",
       "                 1.4          0.726807  0.000000  0.000000  0.456373   \n",
       "70               0.2          0.831464  0.078968  0.439842  0.994524   \n",
       "                 0.4          0.864014  0.000000  0.261525  0.993303   \n",
       "                 0.6          0.833946  0.000000  0.270415  0.993090   \n",
       "                 0.8          0.815616  0.000000  0.222538  0.992434   \n",
       "                 1.0          0.771279  0.000000  0.127185  0.991320   \n",
       "                 1.2          0.760423  0.000000  0.118696  0.989703   \n",
       "                 1.4          0.737993  0.000000  0.000000  0.460965   \n",
       "80               0.2          0.847836  0.084026  0.458009  0.996964   \n",
       "                 0.4          0.762701  0.061270  0.287378  0.993364   \n",
       "                 0.6          0.843862  0.055021  0.200298  0.993151   \n",
       "                 0.8          0.823477  0.000000  0.129465  0.992892   \n",
       "                 1.0          0.799438  0.000000  0.117191  0.992159   \n",
       "                 1.2          0.765851  0.000000  0.131300  0.990893   \n",
       "                 1.4          0.758329  0.000000  0.118424  0.989292   \n",
       "90               0.2          0.856967  0.473524  0.478886  0.997132   \n",
       "                 0.4          0.787001  0.069120  0.299953  0.993303   \n",
       "                 0.6          0.852295  0.054511  0.237622  0.993212   \n",
       "                 0.8          0.831745  0.058478  0.278846  0.993029   \n",
       "                 1.0          0.816856  0.000000  0.225205  0.992571   \n",
       "                 1.2          0.786720  0.000000  0.121378  0.991763   \n",
       "                 1.4          0.761799  0.000000  0.131429  0.990573   \n",
       "100              0.2          0.870169  0.500829  0.531839  0.997270   \n",
       "                 0.4          0.774100  0.074079  0.329964  0.993380   \n",
       "                 0.6          0.859730  0.045839  0.246326  0.993303   \n",
       "                 0.8          0.838666  0.052428  0.152235  0.993136   \n",
       "                 1.0          0.823399  0.061355  0.129465  0.992876   \n",
       "                 1.2          0.807183  0.000000  0.220631  0.992297   \n",
       "                 1.4          0.776184  0.000000  0.127558  0.991564   \n",
       "110              0.2          0.881278  0.483159  0.514016  0.997331   \n",
       "                 0.4          0.793670  0.082369  0.354526  0.993441   \n",
       "                 0.6          0.867659  0.052584  0.277082  0.993303   \n",
       "                 0.8          0.845946  0.060590  0.209819  0.993181   \n",
       "                 1.0          0.830253  0.061624  0.281785  0.993029   \n",
       "                 1.2          0.818310  0.052811  0.222136  0.992663   \n",
       "                 1.4          0.796065  0.000000  0.118854  0.992037   \n",
       "120              0.2          0.882567  0.434982  0.449836  0.997346   \n",
       "                 0.4          0.808559  0.085571  0.393771  0.993563   \n",
       "                 0.6          0.762701  0.061270  0.287378  0.993364   \n",
       "                 0.8          0.852295  0.054511  0.237622  0.993212   \n",
       "                 1.0          0.835584  0.052740  0.270601  0.993105   \n",
       "                 1.2          0.823399  0.061582  0.129465  0.992876   \n",
       "                 1.4          0.812369  0.053037  0.223656  0.992358   \n",
       "\n",
       "                                    38        39        40        41  \\\n",
       "min_cluster_size min_samples                                           \n",
       "40               0.2          0.900483  0.998253  0.996994  0.998770   \n",
       "                 0.4          0.850575  0.998253  0.996421  0.998447   \n",
       "                 0.6          0.792171  0.998253  0.995563  0.998382   \n",
       "                 0.8          0.871531  0.998253  0.994561  0.998317   \n",
       "                 1.0          0.620490  0.998253  0.993988  0.998252   \n",
       "                 1.2          0.549792  0.998253  0.993630  0.998252   \n",
       "                 1.4          0.753956  0.997939  0.992843  0.998188   \n",
       "50               0.2          0.936732  0.998253  0.998068  0.998770   \n",
       "                 0.4          0.857904  0.998253  0.997495  0.998706   \n",
       "                 0.6          0.836415  0.998253  0.995849  0.998447   \n",
       "                 0.8          0.781742  0.998253  0.995419  0.998382   \n",
       "                 1.0          0.871198  0.998253  0.994561  0.998317   \n",
       "                 1.2          0.638681  0.998253  0.993988  0.998252   \n",
       "                 1.4          0.567583  0.998253  0.993773  0.998252   \n",
       "60               0.2          0.940830  0.998253  0.998425  0.998706   \n",
       "                 0.4          0.881759  0.998253  0.997638  0.998706   \n",
       "                 0.6          0.846777  0.998253  0.996421  0.998447   \n",
       "                 0.8          0.816492  0.998253  0.995706  0.998447   \n",
       "                 1.0          0.770381  0.998253  0.995276  0.998382   \n",
       "                 1.2          0.871198  0.998253  0.994561  0.998317   \n",
       "                 1.4          0.651308  0.998253  0.994203  0.998252   \n",
       "70               0.2          0.874863  0.998253  0.998712  0.998835   \n",
       "                 0.4          0.897818  0.998253  0.996994  0.998706   \n",
       "                 0.6          0.848209  0.998253  0.997495  0.998706   \n",
       "                 0.8          0.838781  0.998253  0.996064  0.998511   \n",
       "                 1.0          0.802299  0.998253  0.995563  0.998447   \n",
       "                 1.2          0.764118  0.998253  0.995133  0.998317   \n",
       "                 1.4          0.871531  0.998253  0.994561  0.998317   \n",
       "80               0.2          0.888056  0.998253  0.998926  0.998835   \n",
       "                 0.4          0.924338  0.998253  0.996994  0.998770   \n",
       "                 0.6          0.866800  0.998253  0.997567  0.998706   \n",
       "                 0.8          0.846777  0.998253  0.996421  0.998447   \n",
       "                 1.0          0.825054  0.998253  0.995849  0.998447   \n",
       "                 1.2          0.791271  0.998253  0.995563  0.998382   \n",
       "                 1.4          0.757754  0.998253  0.995133  0.998317   \n",
       "90               0.2          0.900716  0.998253  0.998855  0.998900   \n",
       "                 0.4          0.920307  0.998253  0.998211  0.998770   \n",
       "                 0.6          0.881759  0.998253  0.997638  0.998706   \n",
       "                 0.8          0.851508  0.998253  0.997495  0.998706   \n",
       "                 1.0          0.841846  0.998253  0.996064  0.998511   \n",
       "                 1.2          0.813427  0.998253  0.995706  0.998447   \n",
       "                 1.4          0.785141  0.998253  0.995419  0.998382   \n",
       "100              0.2          0.907846  0.998253  0.998926  0.998511   \n",
       "                 0.4          0.936732  0.998253  0.998068  0.998770   \n",
       "                 0.6          0.904548  0.998253  0.996994  0.998706   \n",
       "                 0.8          0.857904  0.998253  0.997495  0.998706   \n",
       "                 1.0          0.846477  0.998253  0.996350  0.998447   \n",
       "                 1.2          0.832417  0.998253  0.995849  0.998447   \n",
       "                 1.4          0.803098  0.998253  0.995563  0.998447   \n",
       "110              0.2          0.979810  0.998253  0.998926  0.998900   \n",
       "                 0.4          0.935199  0.998253  0.998211  0.998706   \n",
       "                 0.6          0.902549  0.998253  0.996994  0.998770   \n",
       "                 0.8          0.871064  0.998253  0.997567  0.998706   \n",
       "                 1.0          0.848476  0.998253  0.997423  0.998706   \n",
       "                 1.2          0.843711  0.998253  0.996135  0.998511   \n",
       "                 1.4          0.822289  0.998253  0.995777  0.998447   \n",
       "120              0.2          0.980010  0.998253  0.998998  0.998835   \n",
       "                 0.4          0.940830  0.998253  0.998425  0.998706   \n",
       "                 0.6          0.924338  0.998253  0.996994  0.998770   \n",
       "                 0.8          0.881759  0.998253  0.997638  0.998706   \n",
       "                 1.0          0.851374  0.998253  0.997495  0.998706   \n",
       "                 1.2          0.846477  0.998253  0.996421  0.998447   \n",
       "                 1.4          0.835682  0.998253  0.995920  0.998447   \n",
       "\n",
       "                                    42        45        46        47  \\\n",
       "min_cluster_size min_samples                                           \n",
       "40               0.2          0.000000  0.743189  0.992478  0.971963   \n",
       "                 0.4          0.000000  0.613838  0.986408  0.961151   \n",
       "                 0.6          0.000000  0.656729  0.982449  0.999542   \n",
       "                 0.8          0.000000  0.614927  0.975851  0.999725   \n",
       "                 1.0          0.000000  0.549779  0.965690  0.994686   \n",
       "                 1.2          0.000000  0.537275  0.997493  0.994502   \n",
       "                 1.4          0.000000  0.535510  0.997361  0.994319   \n",
       "50               0.2          0.161797  0.767375  0.966614  0.985065   \n",
       "                 0.4          0.000000  0.673750  0.988783  0.984332   \n",
       "                 0.6          0.000000  0.671225  0.985352  0.976636   \n",
       "                 0.8          0.000000  0.635582  0.981394  0.967565   \n",
       "                 1.0          0.000000  0.614927  0.975851  0.953271   \n",
       "                 1.2          0.000000  0.563802  0.969121  0.994961   \n",
       "                 1.4          0.000000  0.531116  0.965294  0.994502   \n",
       "60               0.2          0.178813  0.829401  0.973212  0.981583   \n",
       "                 0.4          0.261136  0.699415  0.990367  0.984607   \n",
       "                 0.6          0.000000  0.613838  0.986408  0.973520   \n",
       "                 0.8          0.000000  0.673894  0.984297  0.968756   \n",
       "                 1.0          0.000000  0.625069  0.980206  0.958219   \n",
       "                 1.2          0.000000  0.614927  0.975851  0.953271   \n",
       "                 1.4          0.000000  0.574171  0.970177  0.995327   \n",
       "70               0.2          0.202626  0.836013  0.975059  0.982225   \n",
       "                 0.4          0.000000  0.717873  0.991423  0.973704   \n",
       "                 0.6          0.000000  0.656750  0.987860  0.976910   \n",
       "                 0.8          0.000000  0.612011  0.985616  0.971138   \n",
       "                 1.0          0.000000  0.671266  0.983109  0.964266   \n",
       "                 1.2          0.000000  0.616795  0.979810  0.956753   \n",
       "                 1.4          0.000000  0.614927  0.975851  0.953271   \n",
       "80               0.2          0.226651  0.856894  0.975851  0.983691   \n",
       "                 0.4          0.182898  0.743065  0.992478  0.976544   \n",
       "                 0.6          0.171730  0.688307  0.989179  0.979384   \n",
       "                 0.8          0.000000  0.613120  0.986408  0.973520   \n",
       "                 1.0          0.000000  0.675044  0.985088  0.968298   \n",
       "                 1.2          0.000000  0.656319  0.982449  0.962892   \n",
       "                 1.4          0.000000  0.616508  0.979282  0.956020   \n",
       "90               0.2          0.999631  0.867858  0.976907  0.983324   \n",
       "                 0.4          0.999546  0.760497  0.944840  0.978651   \n",
       "                 0.6          0.999588  0.699415  0.990367  0.970405   \n",
       "                 0.8          0.999641  0.647531  0.987596  0.975536   \n",
       "                 1.0          0.999609  0.619793  0.985616  0.968114   \n",
       "                 1.2          0.000000  0.520316  0.984297  0.961884   \n",
       "                 1.4          0.000000  0.644985  0.981789  0.955562   \n",
       "100              0.2          0.999683  0.998399  0.978094  0.983049   \n",
       "                 0.4          0.999546  0.767375  0.946688  0.981308   \n",
       "                 0.6          0.999546  0.708100  0.991291  0.972787   \n",
       "                 0.8          0.999683  0.673750  0.988783  0.978285   \n",
       "                 1.0          0.999588  0.613120  0.986408  0.973245   \n",
       "                 1.2          0.238790  0.535612  0.985352  0.969855   \n",
       "                 1.4          0.000000  0.516641  0.983901  0.964724   \n",
       "110              0.2          0.999683  0.998481  0.960940  0.976086   \n",
       "                 0.4          0.999557  0.997659  0.971364  0.980117   \n",
       "                 0.6          0.999536  0.728118  0.991686  0.974620   \n",
       "                 0.8          0.999641  0.693399  0.989311  0.981675   \n",
       "                 1.0          0.999641  0.640756  0.987200  0.974895   \n",
       "                 1.2          0.999599  0.625542  0.985616  0.968389   \n",
       "                 1.4          0.239898  0.523560  0.984429  0.967473   \n",
       "120              0.2          0.999989  0.998481  0.963051  0.976544   \n",
       "                 0.4          0.999557  0.997762  0.954605  0.981583   \n",
       "                 0.6          0.999536  0.996263  0.992478  0.975994   \n",
       "                 0.8          0.999588  0.699415  0.990367  0.970405   \n",
       "                 1.0          0.999662  0.663546  0.988124  0.977277   \n",
       "                 1.2          0.999588  0.613120  0.986408  0.973245   \n",
       "                 1.4          0.235972  0.543989  0.985616  0.966465   \n",
       "\n",
       "                                    48        49      50        51        53  \\\n",
       "min_cluster_size min_samples                                                   \n",
       "40               0.2          0.785726  0.880925  0.9836  0.998713  0.713366   \n",
       "                 0.4          0.846117  0.983667  0.9832  0.997427  0.612104   \n",
       "                 0.6          0.822747  0.970010  0.9832  0.986951  0.568849   \n",
       "                 0.8          0.953497  0.967547  0.9832  0.986767  0.513923   \n",
       "                 1.0          0.946687  0.964614  0.9736  0.986400  0.518477   \n",
       "                 1.2          0.918684  0.934087  0.9624  0.986216  0.471678   \n",
       "                 1.4          0.913006  0.928445  0.9592  0.986032  0.384815   \n",
       "50               0.2          0.818513  0.910724  0.9828  0.998713  0.729130   \n",
       "                 0.4          0.775393  0.986388  0.9828  0.997427  0.654430   \n",
       "                 0.6          0.834287  0.971353  0.9824  0.997243  0.626258   \n",
       "                 0.8          0.819407  0.969518  0.9824  0.986951  0.557231   \n",
       "                 1.0          0.806607  0.967547  0.9824  0.986583  0.513732   \n",
       "                 1.2          0.947991  0.965443  0.9780  0.986400  0.468323   \n",
       "                 1.4          0.929082  0.936326  0.9636  0.986216  0.490114   \n",
       "60               0.2          0.811122  0.924684  0.9828  0.998713  0.737148   \n",
       "                 0.4          0.737607  0.987630  0.9972  0.998713  0.689230   \n",
       "                 0.6          0.846117  0.983667  0.9828  0.997427  0.636785   \n",
       "                 0.8          0.826648  0.970693  0.9824  0.997059  0.610958   \n",
       "                 1.0          0.817748  0.969204  0.9824  0.986767  0.550004   \n",
       "                 1.2          0.806607  0.967547  0.9824  0.986583  0.513923   \n",
       "                 1.4          0.979755  0.965812  0.9820  0.986583  0.476559   \n",
       "70               0.2          0.826734  0.934714  0.9828  0.998713  0.741457   \n",
       "                 0.4          0.763853  0.989343  0.9972  0.998713  0.715439   \n",
       "                 0.6          0.983170  0.987529  0.9828  0.997427  0.646740   \n",
       "                 0.8          0.838133  0.973939  0.9824  0.997427  0.632612   \n",
       "                 1.0          0.824396  0.970223  0.9824  0.987135  0.596176   \n",
       "                 1.2          0.815981  0.969070  0.9824  0.986767  0.544577   \n",
       "                 1.4          0.806607  0.967547  0.9824  0.986583  0.513732   \n",
       "80               0.2          0.810626  0.895959  0.9972  0.997059  0.741457   \n",
       "                 0.4          0.785726  0.880678  0.9968  0.997611  0.729593   \n",
       "                 0.6          0.984334  0.988526  0.9972  0.996508  0.691112   \n",
       "                 0.8          0.982847  0.983589  0.9972  0.996508  0.636785   \n",
       "                 1.0          0.826842  0.971107  0.9968  0.997059  0.620476   \n",
       "                 1.2          0.822747  0.969999  0.9824  0.986951  0.586195   \n",
       "                 1.4          0.815054  0.968935  0.9824  0.986767  0.540622   \n",
       "90               0.2          0.823965  0.994380  0.9972  0.997059  0.744375   \n",
       "                 0.4          0.805842  0.893317  0.9968  0.997611  0.727275   \n",
       "                 0.6          0.737607  0.987630  0.9972  0.997611  0.704148   \n",
       "                 0.8          0.982944  0.985940  0.9968  0.996508  0.657567   \n",
       "                 1.0          0.965780  0.976313  0.9964  0.996324  0.636512   \n",
       "                 1.2          0.826648  0.970693  0.9964  0.997059  0.610958   \n",
       "                 1.4          0.820668  0.969865  0.9824  0.986951  0.578531   \n",
       "100              0.2          0.835117  0.994582  0.9972  0.997059  0.767802   \n",
       "                 0.4          0.818513  0.992298  0.9972  0.997611  0.735593   \n",
       "                 0.6          0.989301  0.988783  0.9972  0.997611  0.712766   \n",
       "                 0.8          0.775393  0.986388  0.9972  0.996508  0.668803   \n",
       "                 1.0          0.982847  0.983589  0.9968  0.996508  0.649085   \n",
       "                 1.2          0.965133  0.971331  0.9968  0.995773  0.626258   \n",
       "                 1.4          0.825495  0.970290  0.9824  0.987135  0.600322   \n",
       "110              0.2          0.826562  0.810176  0.9976  0.997243  0.773311   \n",
       "                 0.4          0.780155  0.856801  0.9972  0.997611  0.748275   \n",
       "                 0.6          0.823275  0.868577  0.9968  0.997611  0.711130   \n",
       "                 0.8          0.984840  0.987126  0.9968  0.996876  0.692721   \n",
       "                 1.0          0.982922  0.985582  0.9968  0.996508  0.654321   \n",
       "                 1.2          0.982825  0.977723  0.9964  0.996324  0.646494   \n",
       "                 1.4          0.828048  0.970950  0.9968  0.993935  0.617694   \n",
       "120              0.2          0.767355  0.991515  0.9976  0.997243  0.774048   \n",
       "                 0.4          0.778938  0.988973  0.9968  0.997611  0.737148   \n",
       "                 0.6          0.835666  0.877454  0.9968  0.997611  0.718112   \n",
       "                 0.8          0.737607  0.984630  0.9972  0.997611  0.704094   \n",
       "                 1.0          0.983396  0.986242  0.9968  0.996508  0.676657   \n",
       "                 1.2          0.982847  0.983589  0.9972  0.996508  0.649276   \n",
       "                 1.4          0.982804  0.972372  0.9968  0.995957  0.640276   \n",
       "\n",
       "                                    55        56        57        58  \\\n",
       "min_cluster_size min_samples                                           \n",
       "40               0.2          0.877282  0.824202  0.927386  0.985382   \n",
       "                 0.4          0.753631  0.738024  0.871920  0.976605   \n",
       "                 0.6          0.714330  0.592166  0.833161  0.964025   \n",
       "                 0.8          0.673618  0.640218  0.790823  0.951071   \n",
       "                 1.0          0.638084  0.669387  0.749977  0.933619   \n",
       "                 1.2          0.592647  0.613037  0.710822  0.926607   \n",
       "                 1.4          0.567392  0.567320  0.665332  0.921531   \n",
       "50               0.2          0.881864  0.999491  0.945037  0.986724   \n",
       "                 0.4          0.823832  0.999453  0.898617  0.980238   \n",
       "                 0.6          0.749670  0.999019  0.856553  0.973023   \n",
       "                 0.8          0.696880  0.649361  0.824998  0.961394   \n",
       "                 1.0          0.673618  0.624130  0.790655  0.951003   \n",
       "                 1.2          0.645929  0.627013  0.758886  0.937286   \n",
       "                 1.4          0.613411  0.630975  0.721117  0.922057   \n",
       "60               0.2          0.892466  0.999528  0.814748  0.987674   \n",
       "                 0.4          0.845592  0.999453  0.912308  0.982768   \n",
       "                 0.6          0.778977  0.999404  0.871828  0.976605   \n",
       "                 0.8          0.730356  0.997068  0.846563  0.970697   \n",
       "                 1.0          0.710667  0.996745  0.819332  0.959781   \n",
       "                 1.2          0.673515  0.624130  0.790655  0.951071   \n",
       "                 1.4          0.650783  0.632727  0.764765  0.939679   \n",
       "70               0.2          0.872828  0.999528  0.856645  0.988201   \n",
       "                 0.4          0.863508  0.999478  0.920807  0.984126   \n",
       "                 0.6          0.808828  0.999453  0.883768  0.979050   \n",
       "                 0.8          0.757087  0.999304  0.860939  0.974110   \n",
       "                 1.0          0.733786  0.997056  0.838689  0.965808   \n",
       "                 1.2          0.705916  0.996410  0.815860  0.958643   \n",
       "                 1.4          0.673618  0.624130  0.790655  0.951071   \n",
       "80               0.2          0.885838  0.999528  0.880981  0.989202   \n",
       "                 0.4          0.877282  0.999478  0.927386  0.985382   \n",
       "                 0.6          0.831974  0.999453  0.904389  0.981189   \n",
       "                 0.8          0.769605  0.999404  0.871920  0.976605   \n",
       "                 1.0          0.740751  0.997515  0.852670  0.972004   \n",
       "                 1.2          0.733566  0.997056  0.833161  0.963991   \n",
       "                 1.4          0.700738  0.996049  0.812662  0.957896   \n",
       "90               0.2          0.892531  0.999553  0.890941  0.988489   \n",
       "                 0.4          0.872259  0.999478  0.939752  0.986062   \n",
       "                 0.6          0.841010  0.999453  0.912308  0.982734   \n",
       "                 0.8          0.795780  0.999453  0.881134  0.978676   \n",
       "                 1.0          0.756686  0.999329  0.863605  0.974840   \n",
       "                 1.2          0.730356  0.997068  0.846563  0.970680   \n",
       "                 1.4          0.720427  0.997056  0.828272  0.962361   \n",
       "100              0.2          0.894162  0.999553  0.908379  0.988693   \n",
       "                 0.4          0.999650  0.999491  0.802321  0.985994   \n",
       "                 0.6          0.999650  0.999478  0.918141  0.983702   \n",
       "                 0.8          0.817890  0.999453  0.898617  0.980204   \n",
       "                 1.0          0.771547  0.999404  0.871828  0.976605   \n",
       "                 1.2          0.742951  0.999019  0.856553  0.972989   \n",
       "                 1.4          0.736557  0.997068  0.841567  0.966538   \n",
       "110              0.2          0.899689  0.999553  0.999909  0.989118   \n",
       "                 0.4          0.999650  0.999516  0.999650  0.986673   \n",
       "                 0.6          0.999650  0.999478  0.999543  0.984669   \n",
       "                 0.8          0.999534  0.999466  0.999330  0.981512   \n",
       "                 1.0          0.786693  0.999441  0.879413  0.978354   \n",
       "                 1.2          0.759508  0.999329  0.865371  0.975213   \n",
       "                 1.4          0.729748  0.997118  0.851071  0.971699   \n",
       "120              0.2          0.893463  0.999553  0.999924  0.998625   \n",
       "                 0.4          0.999663  0.999528  0.999665  0.996486   \n",
       "                 0.6          0.999650  0.999478  0.999558  0.994194   \n",
       "                 0.8          0.999638  0.999453  0.999376  0.999830   \n",
       "                 1.0          0.999055  0.999453  0.998843  0.999830   \n",
       "                 1.2          0.767288  0.999404  0.871828  0.976605   \n",
       "                 1.4          0.748298  0.999267  0.858944  0.973804   \n",
       "\n",
       "                                    59        60        61        62  \\\n",
       "min_cluster_size min_samples                                           \n",
       "40               0.2          0.992887  0.993428  0.949630  0.000000   \n",
       "                 0.4          0.991015  0.976829  0.981956  0.000000   \n",
       "                 0.6          0.972878  0.974238  0.879041  0.000000   \n",
       "                 0.8          0.965312  0.972998  0.965205  0.000000   \n",
       "                 1.0          0.951343  0.970219  0.960562  0.000000   \n",
       "                 1.2          0.939881  0.969205  0.827495  0.000000   \n",
       "                 1.4          0.925248  0.967853  0.956154  0.000000   \n",
       "50               0.2          0.987134  0.994742  0.988304  0.741559   \n",
       "                 0.4          0.991558  0.978369  0.985130  0.000000   \n",
       "                 0.6          0.976517  0.975777  0.887504  0.000000   \n",
       "                 0.8          0.971232  0.973900  0.875044  0.000000   \n",
       "                 1.0          0.965297  0.972961  0.965205  0.000000   \n",
       "                 1.2          0.954968  0.970520  0.961444  0.000000   \n",
       "                 1.4          0.943536  0.968905  0.958799  0.000000   \n",
       "60               0.2          0.988251  0.995606  0.989656  0.986053   \n",
       "                 0.4          0.991830  0.991963  0.931174  0.987773   \n",
       "                 0.6          0.991015  0.976829  0.981956  0.986689   \n",
       "                 0.8          0.974901  0.975064  0.885976  0.985119   \n",
       "                 1.0          0.970462  0.973787  0.873457  0.000000   \n",
       "                 1.2          0.965312  0.972961  0.965205  0.000000   \n",
       "                 1.4          0.957097  0.970933  0.961855  0.000000   \n",
       "70               0.2          0.989021  0.996019  0.990008  0.986577   \n",
       "                 0.4          0.992691  0.992865  0.932644  0.988895   \n",
       "                 0.6          0.991498  0.977880  0.984307  0.987362   \n",
       "                 0.8          0.977469  0.976040  0.886740  0.985792   \n",
       "                 1.0          0.973603  0.974613  0.881333  0.984633   \n",
       "                 1.2          0.969737  0.973562  0.872223  0.981791   \n",
       "                 1.4          0.965297  0.972998  0.965205  0.000000   \n",
       "80               0.2          0.969133  0.996507  0.988245  0.986315   \n",
       "                 0.4          0.992887  0.993428  0.949630  0.987886   \n",
       "                 0.6          0.991468  0.991625  0.924004  0.987474   \n",
       "                 0.8          0.991015  0.976829  0.981956  0.986689   \n",
       "                 1.0          0.975808  0.975439  0.888621  0.985380   \n",
       "                 1.2          0.972878  0.974238  0.879041  0.984147   \n",
       "                 1.4          0.966943  0.973524  0.870930  0.980632   \n",
       "90               0.2          0.971171  0.997784  0.991654  0.992148   \n",
       "                 0.4          0.986877  0.994029  0.930293  0.986839   \n",
       "                 0.6          0.991830  0.991963  0.931174  0.987773   \n",
       "                 0.8          0.991528  0.977655  0.983837  0.987175   \n",
       "                 1.0          0.977786  0.976303  0.886388  0.986016   \n",
       "                 1.2          0.974901  0.975064  0.885976  0.985119   \n",
       "                 1.4          0.972032  0.973975  0.876984  0.983287   \n",
       "100              0.2          0.968982  0.996808  0.702363  0.991812   \n",
       "                 0.4          0.987134  0.994742  0.988304  0.987586   \n",
       "                 0.6          0.992479  0.992414  0.919008  0.988746   \n",
       "                 0.8          0.991558  0.978369  0.891207  0.987400   \n",
       "                 1.0          0.991015  0.976829  0.883684  0.986689   \n",
       "                 1.2          0.976517  0.975777  0.887504  0.985642   \n",
       "                 1.4          0.974071  0.974801  0.883214  0.984782   \n",
       "110              0.2          0.970326  0.996019  0.702892  0.992858   \n",
       "                 0.4          0.987632  0.995306  0.989420  0.987250   \n",
       "                 0.6          0.992676  0.993090  0.987011  0.989007   \n",
       "                 0.8          0.991558  0.991625  0.920889  0.987586   \n",
       "                 1.0          0.991513  0.977430  0.983308  0.987063   \n",
       "                 1.2          0.977831  0.976416  0.885800  0.986128   \n",
       "                 1.4          0.975581  0.975327  0.888210  0.985343   \n",
       "120              0.2          0.971368  0.997071  0.705595  0.993382   \n",
       "                 0.4          0.988251  0.995606  0.989656  0.986053   \n",
       "                 0.6          0.992887  0.993428  0.949630  0.987886   \n",
       "                 0.8          0.991830  0.991963  0.931174  0.987773   \n",
       "                 1.0          0.991498  0.978031  0.984836  0.987362   \n",
       "                 1.2          0.991015  0.976829  0.981956  0.986689   \n",
       "                 1.4          0.976955  0.975928  0.887446  0.985717   \n",
       "\n",
       "                                    63        64        65        66  \\\n",
       "min_cluster_size min_samples                                           \n",
       "40               0.2          0.341353  0.994643  0.994635  0.982352   \n",
       "                 0.4          0.000000  0.991161  0.993711  0.975312   \n",
       "                 0.6          0.000000  0.984180  0.992846  0.974352   \n",
       "                 0.8          0.000000  0.981483  0.991471  0.969014   \n",
       "                 1.0          0.000000  0.979037  0.989407  0.967111   \n",
       "                 1.2          0.000000  0.976252  0.982273  0.962817   \n",
       "                 1.4          0.000000  0.972752  0.984474  0.961015   \n",
       "50               0.2          0.292481  0.995304  0.994831  0.984625   \n",
       "                 0.4          0.000000  0.992661  0.994026  0.977653   \n",
       "                 0.6          0.000000  0.987697  0.993554  0.974454   \n",
       "                 0.8          0.000000  0.983394  0.992610  0.973292   \n",
       "                 1.0          0.000000  0.981483  0.991471  0.968997   \n",
       "                 1.2          0.000000  0.979519  0.989938  0.967684   \n",
       "                 1.4          0.000000  0.977269  0.986243  0.964484   \n",
       "60               0.2          1.000000  0.995697  0.995244  0.986511   \n",
       "                 0.4          1.000000  0.993411  0.994261  0.979573   \n",
       "                 0.6          1.000000  0.991161  0.993711  0.975296   \n",
       "                 0.8          1.000000  0.985876  0.993239  0.974437   \n",
       "                 1.0          0.000000  0.983073  0.992394  0.972534   \n",
       "                 1.2          0.000000  0.981483  0.991471  0.968997   \n",
       "                 1.4          0.000000  0.979734  0.989977  0.967515   \n",
       "70               0.2          1.000000  0.996000  0.995460  0.987959   \n",
       "                 0.4          1.000000  0.994036  0.994379  0.981021   \n",
       "                 0.6          1.000000  0.992161  0.993986  0.976996   \n",
       "                 0.8          1.000000  0.988715  0.993554  0.974571   \n",
       "                 1.0          1.000000  0.984930  0.993043  0.974470   \n",
       "                 1.2          0.000000  0.982823  0.992335  0.972029   \n",
       "                 1.4          0.000000  0.981483  0.991471  0.968997   \n",
       "80               0.2          1.000000  0.996197  0.995598  0.988498   \n",
       "                 0.4          1.000000  0.994643  0.994635  0.982352   \n",
       "                 0.6          1.000000  0.992965  0.994104  0.978394   \n",
       "                 0.8          1.000000  0.991161  0.993711  0.975312   \n",
       "                 1.0          1.000000  0.986858  0.993416  0.974352   \n",
       "                 1.2          1.000000  0.984180  0.992846  0.974352   \n",
       "                 1.4          0.000000  0.982662  0.992237  0.971675   \n",
       "90               0.2          1.000000  0.996357  0.995834  0.989357   \n",
       "                 0.4          1.000000  0.994875  0.994772  0.983598   \n",
       "                 0.6          1.000000  0.993411  0.994261  0.979590   \n",
       "                 0.8          1.000000  0.992018  0.993967  0.976559   \n",
       "                 1.0          1.000000  0.989429  0.993613  0.974319   \n",
       "                 1.2          1.000000  0.985858  0.993239  0.974420   \n",
       "                 1.4          1.000000  0.983858  0.992768  0.973847   \n",
       "100              0.2          1.000000  0.996572  0.996404  0.991950   \n",
       "                 0.4          1.000000  0.995304  0.994831  0.984625   \n",
       "                 0.6          1.000000  0.993840  0.994320  0.980567   \n",
       "                 0.8          1.000000  0.992661  0.994026  0.977653   \n",
       "                 1.0          1.000000  0.991126  0.993711  0.975296   \n",
       "                 1.2          1.000000  0.987697  0.993554  0.974454   \n",
       "                 1.4          1.000000  0.985162  0.993063  0.974386   \n",
       "110              0.2          1.000000  0.996554  0.996443  0.990452   \n",
       "                 0.4          1.000000  0.995572  0.995028  0.985450   \n",
       "                 0.6          1.000000  0.994250  0.994438  0.981526   \n",
       "                 0.8          1.000000  0.993072  0.994202  0.978680   \n",
       "                 1.0          1.000000  0.991876  0.993888  0.976306   \n",
       "                 1.2          1.000000  0.989786  0.993632  0.974369   \n",
       "                 1.4          1.000000  0.986608  0.993397  0.974538   \n",
       "120              0.2          1.000000  0.985590  0.996404  0.992691   \n",
       "                 0.4          1.000000  0.995697  0.995244  0.986511   \n",
       "                 0.6          1.000000  0.994643  0.994635  0.982352   \n",
       "                 0.8          1.000000  0.993411  0.994261  0.979573   \n",
       "                 1.0          1.000000  0.992322  0.993986  0.977249   \n",
       "                 1.2          1.000000  0.991161  0.993711  0.975296   \n",
       "                 1.4          1.000000  0.988394  0.993534  0.974437   \n",
       "\n",
       "                                    67        68        69        71        72  \n",
       "min_cluster_size min_samples                                                    \n",
       "40               0.2          0.991610  0.776938  0.782480  0.996963  0.359460  \n",
       "                 0.4          0.981277  0.700702  0.494038  0.996302  0.336371  \n",
       "                 0.6          0.977021  0.655459  0.433170  0.995686  0.000000  \n",
       "                 0.8          0.971591  0.622066  0.380563  0.994894  0.000000  \n",
       "                 1.0          0.972082  0.695819  0.354064  0.994013  0.000000  \n",
       "                 1.2          0.971784  0.693589  0.347596  0.993001  0.000000  \n",
       "                 1.4          0.972852  0.685096  0.338010  0.988467  0.000000  \n",
       "50               0.2          0.957054  0.742236  0.809134  0.997315  0.506422  \n",
       "                 0.4          0.982345  0.716332  0.480867  0.996522  0.000000  \n",
       "                 0.6          0.979700  0.685144  0.429974  0.996038  0.000000  \n",
       "                 0.8          0.975935  0.667612  0.430130  0.995466  0.000000  \n",
       "                 1.0          0.971714  0.622066  0.379939  0.994894  0.000000  \n",
       "                 1.2          0.972064  0.586044  0.363806  0.994189  0.000000  \n",
       "                 1.4          0.971679  0.695637  0.327722  0.993529  0.000000  \n",
       "60               0.2          0.964813  0.772406  0.785442  0.997711  0.441732  \n",
       "                 0.4          0.986409  0.676033  0.751929  0.996699  0.418195  \n",
       "                 0.6          0.981277  0.700702  0.492947  0.996302  0.336371  \n",
       "                 0.8          0.978404  0.676941  0.438080  0.995950  0.000000  \n",
       "                 1.0          0.975199  0.665019  0.427792  0.995422  0.000000  \n",
       "                 1.2          0.971714  0.622066  0.379939  0.994894  0.000000  \n",
       "                 1.4          0.971679  0.591788  0.367469  0.994453  0.000000  \n",
       "70               0.2          0.995043  0.783141  0.805471  0.998767  0.999193  \n",
       "                 0.4          0.990612  0.695419  0.536435  0.996919  0.999139  \n",
       "                 0.6          0.982012  0.712127  0.487257  0.996434  0.998672  \n",
       "                 0.8          0.980261  0.690294  0.453511  0.996082  0.000000  \n",
       "                 1.0          0.977651  0.679861  0.441275  0.995774  0.000000  \n",
       "                 1.2          0.974709  0.661372  0.413530  0.995290  0.000000  \n",
       "                 1.4          0.971591  0.622066  0.380563  0.994894  0.000000  \n",
       "80               0.2          0.957702  0.774345  0.853480  0.998503  0.999193  \n",
       "                 0.4          0.991610  0.711618  0.565350  0.996963  0.999175  \n",
       "                 0.6          0.983256  0.658028  0.489673  0.996610  0.999013  \n",
       "                 0.8          0.981277  0.700702  0.494038  0.996302  0.998116  \n",
       "                 1.0          0.903056  0.681703  0.426077  0.995994  0.997488  \n",
       "                 1.2          0.976986  0.655459  0.433170  0.995686  0.000000  \n",
       "                 1.4          0.974446  0.662862  0.422960  0.995246  0.000000  \n",
       "90               0.2          0.996865  0.802794  0.837113  0.998547  0.999193  \n",
       "                 0.4          0.952255  0.729866  0.796275  0.997095  0.999175  \n",
       "                 0.6          0.986409  0.676033  0.753644  0.996699  0.999103  \n",
       "                 0.8          0.981907  0.707184  0.483361  0.996346  0.998547  \n",
       "                 1.0          0.980489  0.691929  0.441821  0.996126  0.997829  \n",
       "                 1.2          0.978404  0.676941  0.438080  0.995950  0.995946  \n",
       "                 1.4          0.976390  0.670447  0.430442  0.995598  0.000000  \n",
       "100              0.2          0.996970  0.810948  0.845219  0.998547  0.999193  \n",
       "                 0.4          0.957054  0.742115  0.809134  0.997315  0.999175  \n",
       "                 0.6          0.990069  0.689179  0.528486  0.996787  0.999121  \n",
       "                 0.8          0.982380  0.646348  0.480867  0.996522  0.998942  \n",
       "                 1.0          0.981259  0.700702  0.492947  0.996302  0.998116  \n",
       "                 1.2          0.979700  0.685144  0.429974  0.996038  0.997722  \n",
       "                 1.4          0.977896  0.682212  0.445328  0.995862  0.417836  \n",
       "110              0.2          0.997110  0.815383  0.863923  0.998547  0.999193  \n",
       "                 0.4          0.961363  0.759963  0.818175  0.997579  0.999193  \n",
       "                 0.6          0.991015  0.701283  0.549840  0.996919  0.999139  \n",
       "                 0.8          0.984062  0.665043  0.499026  0.996654  0.999013  \n",
       "                 1.0          0.981715  0.627737  0.493648  0.996346  0.998457  \n",
       "                 1.2          0.980664  0.693359  0.446341  0.996214  0.997865  \n",
       "                 1.4          0.901305  0.681170  0.443068  0.995994  0.997291  \n",
       "120              0.2          0.997285  0.825246  0.858312  0.998547  0.999193  \n",
       "                 0.4          0.964813  0.770310  0.785442  0.997711  0.999193  \n",
       "                 0.6          0.991610  0.711618  0.782480  0.996963  0.999175  \n",
       "                 0.8          0.986409  0.675851  0.751929  0.996699  0.999103  \n",
       "                 1.0          0.982082  0.641489  0.485699  0.996478  0.998798  \n",
       "                 1.2          0.981277  0.700702  0.492947  0.996302  0.998116  \n",
       "                 1.4          0.979998  0.687567  0.432234  0.996038  0.997775  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normals_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 0.8825667619832307\n",
      "35 0.5008289289104898\n",
      "36 0.5318392337362527\n",
      "37 0.9973457807065714\n",
      "38 0.9800099950024987\n",
      "39 0.998252531588852\n",
      "40 0.998997995991984\n",
      "41 0.9988996763754046\n",
      "42 0.9999894443506164\n",
      "45 0.9984806488040242\n",
      "46 0.997492742148324\n",
      "47 0.9997251236943376\n",
      "48 0.9893008371852474\n",
      "49 0.9945818873838576\n",
      "50 0.9976\n",
      "51 0.9987134717882742\n",
      "53 0.7740475086590121\n",
      "55 0.999663430420712\n",
      "56 0.9995527728085868\n",
      "57 0.9999238524565196\n",
      "58 0.9998302264778786\n",
      "59 0.9928872378018394\n",
      "60 0.9977842872164638\n",
      "61 0.991653932055954\n",
      "62 0.9933819405496356\n",
      "63 1.0\n",
      "64 0.9965716734518963\n",
      "65 0.9964428198022915\n",
      "66 0.9926913879626824\n",
      "67 0.9972852263770908\n",
      "68 0.8252456593120328\n",
      "69 0.8639233107318214\n",
      "71 0.9987674428841836\n",
      "72 0.9991927092676977\n",
      "Counter({0.2: 57, 0.4: 22, 0.6: 18, 0.8: 18, 1.0: 16, 1.2: 15, 1.4: 12})\n",
      "Counter({120: 34, 110: 22, 100: 21, 90: 19, 70: 16, 80: 15, 60: 13, 40: 10, 50: 8})\n"
     ]
    }
   ],
   "source": [
    "mylist = []\n",
    "for col in normals_scores_df.columns:\n",
    "    print(col,normals_scores_df[col].max())\n",
    "    ## grabs the rows where f1 score is max\n",
    "    mylist.append(normals_scores_df[normals_scores_df[col]==normals_scores_df[col].max()][col])\n",
    "print(Counter([x[1] for ii in mylist for x in ii.index.values ])) ## counts number of times that the min_samples multipler appears\n",
    "print(Counter([x[0] for ii in mylist for x in ii.index.values ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
